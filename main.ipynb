{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from treelib import Node, Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, feature=None, threshold=None, left_child=None, right_child=None, is_leaf=False, value=-1):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(self.feature)\n",
    "        if x[self.feature] < self.threshold:\n",
    "            if self.is_leaf:\n",
    "                return self.value\n",
    "            return self.left_child.forward(x)\n",
    "        else:\n",
    "            if self.is_leaf:\n",
    "                return self.value\n",
    "            return self.right_child.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self, min_samples=1):\n",
    "        self.root_node = Node('root')\n",
    "        self.node_count = 0\n",
    "        self.min_samples = min_samples\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        Y_pred = []\n",
    "        for x_i in X:\n",
    "\n",
    "            curr_node = self.root_node\n",
    "            predicted_y = np.array(self.predict_util(x_i, curr_node))\n",
    "            # print(predicted_y)\n",
    "            Y_pred.append(predicted_y)\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def predict_util(self, x, curr_node):\n",
    "        \n",
    "        if(curr_node.is_leaf):\n",
    "            return curr_node.value\n",
    "        if x[curr_node.feature] <= curr_node.threshold:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.left_child)\n",
    "        else:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.right_child)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.fit_util(X, Y, self.root_node)\n",
    "\n",
    "\n",
    "    def fit_util(self, X, Y, current_node):\n",
    "        if np.unique(Y).shape[0] == 1:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        scores = []\n",
    "        for column in X.columns:\n",
    "            X_train = X[column].to_numpy()\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "            clf = LogisticRegression(random_state=0, max_iter=100)\n",
    "            clf.fit(X_train, Y)\n",
    "            score = clf.score(X_train, Y)\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        best_feature = X.columns[np.argmax(scores)]\n",
    "        best_feature_values = np.unique(X[best_feature])\n",
    "        best_feature_values.sort()\n",
    "\n",
    "        partition = self.get_partition(X, Y, best_feature, best_feature_values)\n",
    "        \n",
    "        if partition == None:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        (X_left, Y_left), (X_right, Y_right), threshold = partition\n",
    "        current_node.threshold = threshold\n",
    "        current_node.feature = best_feature\n",
    "        current_node.name = f'{best_feature} {threshold} {self.node_count}'\n",
    "        self.node_count += 1\n",
    "        current_node.left_child = Node('unnamed')\n",
    "        current_node.right_child = Node('unnamed')\n",
    "\n",
    "        self.fit_util(X_left, Y_left, current_node.left_child)\n",
    "        self.fit_util(X_right, Y_right, current_node.right_child)\n",
    "\n",
    "        \n",
    "\n",
    "    def do_split(self, X, thresh):\n",
    "        \"\"\"\n",
    "            Split the data at a node based on threshold\n",
    "        \"\"\"\n",
    "\n",
    "        left_child_ids = np.where(X <= thresh, True, False)\n",
    "        right_child_ids = np.where(X > thresh, True, False)\n",
    "        return left_child_ids, right_child_ids\n",
    "    \n",
    "    def find_entropy(self, Y):\n",
    "        probs = []\n",
    "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
    "        sort_indices = np.argsort(possible_classes)\n",
    "        possible_classes = possible_classes[sort_indices]\n",
    "        counts = counts[sort_indices]\n",
    "        \n",
    "        for class_label, count in zip(possible_classes, counts):\n",
    "            probs.append(count/Y.shape[0])\n",
    "        \n",
    "        entropy = 0\n",
    "        for prob in probs:\n",
    "            entropy -= prob*np.log2(prob)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def get_partition(self, X, Y, feature, thresholds):\n",
    "        '''\n",
    "            This function should return left and right\n",
    "            partitions according to appropritate\n",
    "            partitioning algorithm. Return None if all\n",
    "            data has same label\n",
    "        '''\n",
    "        \n",
    "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
    "        if(len(Y) < self.min_samples):\n",
    "            return None\n",
    "        \n",
    "        best_info_gain = -float('inf')\n",
    "        best_thresh = thresholds[0]        \n",
    "        for thresh in thresholds[:-1]:\n",
    "\n",
    "            left_child_ids, right_child_ids = self.do_split(X[feature].to_numpy(), thresh)\n",
    "\n",
    "            parent_pts = X.shape[0]\n",
    "            left_child_pts = len(left_child_ids)\n",
    "            right_child_pts = len(right_child_ids)\n",
    "\n",
    "            info_gain = self.find_entropy(Y) - (left_child_pts / parent_pts) * self.find_entropy(Y[left_child_ids]) - (right_child_pts / parent_pts) * self.find_entropy(Y[right_child_ids])\n",
    "\n",
    "            if(info_gain > best_info_gain):\n",
    "\n",
    "                best_info_gain = info_gain\n",
    "                best_thresh = thresh\n",
    "        \n",
    "        # partition according to best threshold\n",
    "        best_left_ids, best_right_ids = self.do_split(X[feature].to_numpy(), best_thresh)\n",
    "        print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "        if(len(Y[best_left_ids]) == 0 or len(Y[best_right_ids]) == 0):\n",
    "            print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "            return None\n",
    "        return (X[best_left_ids], Y[best_left_ids]), (X[best_right_ids], Y[best_right_ids]), best_thresh\n",
    "    \n",
    "    def print_tree(self):\n",
    "        tree = Tree()\n",
    "        self.print_tree_util(self.root_node, tree)\n",
    "        tree.show()\n",
    "        return tree\n",
    "\n",
    "    def print_tree_util(self, root, tree, parent=None):\n",
    "        if parent is not None:\n",
    "            tree.create_node(root.name, root.name, parent=parent.name)\n",
    "        else:\n",
    "            tree.create_node(root.name, root.name)\n",
    "        if root.is_leaf:\n",
    "            return\n",
    "        self.print_tree_util(root.left_child, tree, root)\n",
    "        self.print_tree_util(root.right_child, tree, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = MyDecisionTree(min_samples = 100)\n",
    "X = df.loc[:, df.columns != 'Biopsy']\n",
    "Y = df['Biopsy'].to_numpy()\n",
    "dt.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris, Y_iris = iris.data, iris.target\n",
    "X_iris_train,X_iris_test,Y_iris_train,Y_iris_test=train_test_split(X_iris,Y_iris,test_size=0.2,random_state=42)\n",
    "X_iris_train = pd.DataFrame(X_iris_train)\n",
    "X_iris_test = pd.DataFrame(X_iris_test)\n",
    "\n",
    "print(X_iris_train.shape)\n",
    "print(X_iris_test.shape)\n",
    "\n",
    "# X_iris = pd.DataFrame(X_iris)\n",
    "# print(X_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X_digits, Y_digits = digits.data, digits.target\n",
    "X_digits = X_digits/255\n",
    "X_digits_train,X_digits_test,Y_digits_train,Y_digits_test=train_test_split(X_digits,Y_digits,test_size=0.2,random_state=42)\n",
    "X_digits_train = pd.DataFrame(X_digits_train)\n",
    "X_digits_test = pd.DataFrame(X_digits_test)\n",
    "\n",
    "print(X_digits_train.shape)\n",
    "print(X_digits_test.shape)\n",
    "\n",
    "# X_iris = pd.DataFrame(X_iris)\n",
    "# print(X_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1065\n",
      "372 0\n",
      "372 0\n",
      "249 816\n",
      "249 0\n",
      "249 0\n",
      "276 540\n",
      "276 0\n",
      "276 0\n",
      "540 0\n",
      "540 0\n",
      "34 0.0 0\n",
      "├── 53 0.0 2\n",
      "│   ├── 21 0.0 4\n",
      "│   │   ├── leaf 0 6\n",
      "│   │   └── leaf 6 5\n",
      "│   └── leaf 7 3\n",
      "└── leaf 3 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_digits = MyDecisionTree(min_samples=1)\n",
    "dt_digits.fit(X_digits_train, Y_digits_train)\n",
    "tree = dt_digits.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3472222222222222\n"
     ]
    }
   ],
   "source": [
    "pred_y_digits = dt_digits.predict(X_digits_test.to_numpy()).squeeze()\n",
    "# print(pred_y_digits)\n",
    "\n",
    "accuracy = (pred_y_digits == Y_digits_test).sum() / Y_digits_test.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_iris = MyDecisionTree(min_samples=5)\n",
    "dt_iris.fit(X_iris_train, Y_iris_train)\n",
    "tree = dt_iris.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph tree {\n",
      "\t\"34 0.0 0\" [label=\"34 0.0 0\", shape=circle]\n",
      "\t\"53 0.0 2\" [label=\"53 0.0 2\", shape=circle]\n",
      "\t\"leaf 3 1\" [label=\"leaf 3 1\", shape=circle]\n",
      "\t\"21 0.0 4\" [label=\"21 0.0 4\", shape=circle]\n",
      "\t\"leaf 7 3\" [label=\"leaf 7 3\", shape=circle]\n",
      "\t\"leaf 0 6\" [label=\"leaf 0 6\", shape=circle]\n",
      "\t\"leaf 6 5\" [label=\"leaf 6 5\", shape=circle]\n",
      "\n",
      "\t\"34 0.0 0\" -> \"leaf 3 1\"\n",
      "\t\"34 0.0 0\" -> \"53 0.0 2\"\n",
      "\t\"53 0.0 2\" -> \"leaf 7 3\"\n",
      "\t\"53 0.0 2\" -> \"21 0.0 4\"\n",
      "\t\"21 0.0 4\" -> \"leaf 6 5\"\n",
      "\t\"21 0.0 4\" -> \"leaf 0 6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tree.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = dt_iris.predict(X_iris_test.to_numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_Y, Y_iris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (sum(1 for x,y in zip(pred_Y, Y_iris_test) if x == y) / len(pred_Y))*100\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b1db67202a22c0164e18849e85225c385668d55f66b602110c77d4fc6f23f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
