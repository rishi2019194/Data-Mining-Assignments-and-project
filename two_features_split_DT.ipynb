{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5oJCvGKXAWf1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from treelib import Node, Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "RmdyJe7IAWf4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pJQEku55AWf4"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, name, feature=None, threshold=None, left_child1=None, left_child2=None, right_child1=None, right_child2=None, is_leaf=False, value=-1):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left_child1 = left_child1\n",
        "        self.left_child2 = left_child2\n",
        "        self.right_child1 = right_child1\n",
        "        self.right_child2 = right_child2\n",
        "        self.is_leaf = is_leaf\n",
        "        self.value = value\n",
        "        self.name = name\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5p51j4AzAWf5"
      },
      "outputs": [],
      "source": [
        "class MyDecisionTree:\n",
        "    def __init__(self, min_samples=1):\n",
        "        self.root_node = Node('root')\n",
        "        self.node_count = 0\n",
        "        self.min_samples = min_samples\n",
        "    \n",
        "    def predict(self, X, cols_d):\n",
        "        \n",
        "        Y_pred = []\n",
        "        for i in range(len(X)):\n",
        "\n",
        "            x_i = X[i]\n",
        "            # print(x_i[0])\n",
        "            curr_node = self.root_node\n",
        "            predicted_y = np.array(self.predict_util(x_i, curr_node, cols_d))\n",
        "            # print(predicted_y)\n",
        "            Y_pred.append(predicted_y)\n",
        "\n",
        "        return np.array(Y_pred)\n",
        "\n",
        "    def predict_util(self, x, curr_node, cols_d):\n",
        "        \n",
        "        if(curr_node.is_leaf):\n",
        "            return curr_node.value\n",
        "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.left_child1, cols_d)\n",
        "\n",
        "        if x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.left_child2, cols_d)\n",
        "\n",
        "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.right_child1, cols_d)\n",
        "\n",
        "        elif x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.right_child2, cols_d)\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.fit_util(X, Y, self.root_node)\n",
        "\n",
        "\n",
        "    def fit_util(self, X, Y, current_node):\n",
        "        if np.unique(Y).shape[0] == 1:\n",
        "            current_node.is_leaf = True\n",
        "            unq, counts = np.unique(Y, return_counts=True)\n",
        "            max_freq_idx = np.argmax(counts).flatten()\n",
        "            current_node.value = unq[max_freq_idx].squeeze()\n",
        "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
        "            self.node_count += 1\n",
        "            return\n",
        "            \n",
        "        scores = {}\n",
        "        for column1 in X.columns:\n",
        "            for column2 in X.columns:\n",
        "\n",
        "                column = [column1, column2]\n",
        "                X_train = X[column].to_numpy()\n",
        "                X_train = X_train.reshape(X_train.shape[0], 2)\n",
        "                clf = LogisticRegression(random_state=0)\n",
        "                clf.fit(X_train, Y)\n",
        "                score = clf.score(X_train, Y)\n",
        "                scores[(column1, column2)] = score\n",
        "\n",
        "        scores_sorted = dict( sorted(scores.items(), key=operator.itemgetter(1),reverse=True))\n",
        "        best_feature_set = list(scores_sorted.keys())[0]\n",
        "        best_feature1_values = np.unique(X[best_feature_set[0]])\n",
        "        best_feature2_values = np.unique(X[best_feature_set[1]])\n",
        "\n",
        "        best_feature1_values.sort()\n",
        "        best_feature2_values.sort()\n",
        "\n",
        "        partition = self.get_partition(X, Y, best_feature_set[0], best_feature_set[1], best_feature1_values, best_feature2_values)\n",
        "        \n",
        "        if partition == None:\n",
        "            current_node.is_leaf = True\n",
        "            unq, counts = np.unique(Y, return_counts=True)\n",
        "            max_freq_idx = np.argmax(counts).flatten()\n",
        "            current_node.value = unq[max_freq_idx].squeeze()\n",
        "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
        "            self.node_count += 1\n",
        "            return\n",
        "            \n",
        "        (X_left1, Y_left1), (X_left2, Y_left2), (X_right1, Y_right1), (X_right2, Y_right2), threshold1, threshold2 = partition\n",
        "\n",
        "        threshold = [threshold1, threshold2]\n",
        "        # print(\"Thresholds: \",threshold)\n",
        "        current_node.threshold = threshold\n",
        "        current_node.feature = best_feature_set\n",
        "        current_node.name = f'{best_feature_set} {threshold} {self.node_count}'\n",
        "        self.node_count += 1\n",
        "        current_node.left_child1 = Node('unnamed')\n",
        "        current_node.left_child2 = Node('unnamed')\n",
        "        current_node.right_child1 = Node('unnamed')\n",
        "        current_node.right_child2 = Node('unnamed')\n",
        "\n",
        "        if(X_left1.shape[0] == 0):\n",
        "            current_node.left_child1.is_leaf = True\n",
        "            current_node.left_child1.value = 1\n",
        "            current_node.left_child1.name = f'leaf {current_node.left_child1.value} {self.node_count}'\n",
        "            self.node_count+=1 \n",
        "            # return\n",
        "        \n",
        "        if(X_left2.shape[0] == 0):\n",
        "            current_node.left_child2.is_leaf = True\n",
        "            current_node.left_child2.value = 1\n",
        "            current_node.left_child2.name = f'leaf {current_node.left_child2.value} {self.node_count}'\n",
        "            self.node_count+=1 \n",
        "            # return\n",
        "        \n",
        "        if(X_right1.shape[0] == 0):\n",
        "            current_node.right_child1.is_leaf = True\n",
        "            current_node.right_child1.value = 1\n",
        "            current_node.right_child1.name = f'leaf {current_node.right_child1.value} {self.node_count}'\n",
        "            self.node_count+=1   \n",
        "            # return     \n",
        "        \n",
        "        if(X_right2.shape[0] == 0):\n",
        "            current_node.right_child2.is_leaf = True\n",
        "            current_node.right_child2.value = 1\n",
        "            current_node.right_child2.name = f'leaf {current_node.right_child2.value} {self.node_count}'\n",
        "            self.node_count+=1  \n",
        "            # return                  \n",
        "          \n",
        "        if(X_left1.shape[0] != 0):\n",
        "            self.fit_util(X_left1, Y_left1, current_node.left_child1)\n",
        "        \n",
        "        if(X_left2.shape[0] != 0):\n",
        "            self.fit_util(X_left2, Y_left2, current_node.left_child2)\n",
        "        \n",
        "        if(X_right1.shape[0] != 0):\n",
        "            self.fit_util(X_right1, Y_right1, current_node.right_child1)\n",
        "        \n",
        "        if(X_right2.shape[0] != 0):\n",
        "            self.fit_util(X_right2, Y_right2, current_node.right_child2)\n",
        "\n",
        "\n",
        "    def do_split(self, X, thresh):\n",
        "        \"\"\"\n",
        "            Split the data at a node based on threshold\n",
        "        \"\"\"\n",
        "\n",
        "        left_child_ids = np.where(X <= thresh, True, False)\n",
        "        right_child_ids = np.where(X > thresh, True, False)\n",
        "        return left_child_ids, right_child_ids\n",
        "\n",
        "    def do_split_final(self, X1, X2, thresh1, thresh2):\n",
        "\n",
        "        \"\"\"\n",
        "            Split according to the best thresholds for the 2 features\n",
        "        \"\"\"   \n",
        "\n",
        "        left1_ids = np.where(np.logical_and(X1 <= thresh1, X2 <= thresh2), True, False)\n",
        "        left2_ids = np.where(np.logical_and(X1 > thresh1, X2 <= thresh2), True, False)\n",
        "        right1_ids = np.where(np.logical_and(X1 <= thresh1, X2 > thresh2), True, False)\n",
        "        right2_ids = np.where(np.logical_and(X1 > thresh1, X2 > thresh2), True, False)\n",
        "\n",
        "        return left1_ids, left2_ids, right1_ids, right2_ids\n",
        "\n",
        "    def find_entropy(self, Y):\n",
        "        probs = []\n",
        "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
        "        sort_indices = np.argsort(possible_classes)\n",
        "        possible_classes = possible_classes[sort_indices]\n",
        "        counts = counts[sort_indices]\n",
        "        \n",
        "        for class_label, count in zip(possible_classes, counts):\n",
        "            probs.append(count/Y.shape[0])\n",
        "        \n",
        "        entropy = 0\n",
        "        for prob in probs:\n",
        "            entropy -= prob*np.log2(prob)\n",
        "        \n",
        "        return entropy\n",
        "    \n",
        "    def find_best_thresh_info_gain(self, thresholds1, thresholds2, X, Y, feature1, feature2):\n",
        "        \"\"\"\n",
        "            This function finds the best threshold and info gain for a given feature\n",
        "        \"\"\"\n",
        "        best_info_gain = -float('inf')\n",
        "        best_thresh1 = thresholds1[0]   \n",
        "        best_thresh2 = thresholds2[0]     \n",
        "        for thresh1 in thresholds1[:-1]:\n",
        "            for thresh2 in thresholds2[:-1]:\n",
        "\n",
        "                left_child1_ids, left_child2_ids,  right_child1_ids, right_child2_ids = self.do_split_final(X[feature1].to_numpy(),X[feature2].to_numpy(), thresh1, thresh2)\n",
        "\n",
        "                parent_pts = X.shape[0]\n",
        "                left_child1_pts = len(left_child1_ids)\n",
        "                left_child2_pts = len(left_child2_ids)\n",
        "                right_child1_pts = len(right_child1_ids)\n",
        "                right_child2_pts = len(right_child2_ids)\n",
        "\n",
        "                info_gain = self.find_entropy(Y) - (left_child1_pts / parent_pts) * self.find_entropy(Y[left_child1_ids]) - (left_child2_pts / parent_pts) * self.find_entropy(Y[left_child2_ids]) - (right_child1_pts / parent_pts) * self.find_entropy(Y[right_child1_ids]) - (right_child2_pts / parent_pts) * self.find_entropy(Y[right_child2_ids])\n",
        "                \n",
        "                if(info_gain > best_info_gain):\n",
        "\n",
        "                    best_info_gain = info_gain\n",
        "                    best_thresh1 = thresh1\n",
        "                    best_thresh2 = thresh2\n",
        "\n",
        "        \n",
        "        return best_thresh1, best_thresh2, best_info_gain\n",
        "\n",
        "    def get_partition(self, X, Y, feature1, feature2, thresholds1, thresholds2):\n",
        "        '''\n",
        "            This function should return left and right\n",
        "            partitions according to appropritate\n",
        "            partitioning algorithm. Return None if all\n",
        "            data has same label\n",
        "        '''\n",
        "        \n",
        "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
        "        if(len(Y) < self.min_samples):\n",
        "            return None\n",
        "        \n",
        "        best_thresh1, best_thresh2, best_info_gain = self.find_best_thresh_info_gain(thresholds1, thresholds2, X, Y, feature1, feature2)\n",
        "\n",
        "        # partition according to best threshold\n",
        "        best_left_ids1, best_left_ids2, best_right_ids1, best_right_ids2 = self.do_split_final(X[feature1].to_numpy(), X[feature2].to_numpy(), best_thresh1, best_thresh2)\n",
        "\n",
        "        # print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
        "\n",
        "        count_0 = 0\n",
        "        if(len(Y[best_left_ids1]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_left_ids2]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_right_ids1]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_right_ids2]) == 0):\n",
        "            count_0 += 1\n",
        "\n",
        "        if(count_0 == 3):\n",
        "            print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
        "            return None\n",
        "\n",
        "        return (X[best_left_ids1], Y[best_left_ids1]), (X[best_left_ids2], Y[best_left_ids2]), (X[best_right_ids1], Y[best_right_ids1]),(X[best_right_ids2], Y[best_right_ids2]), best_thresh1, best_thresh2    \n",
        "    \n",
        "    def print_tree(self):\n",
        "        tree = Tree()\n",
        "        self.print_tree_util(self.root_node, tree)\n",
        "        tree.show()\n",
        "        return tree\n",
        "\n",
        "    def print_tree_util(self, root, tree, parent=None):\n",
        "        if parent is not None:\n",
        "            print(root.name)\n",
        "            tree.create_node(root.name, root.name, parent=parent.name)\n",
        "        else:\n",
        "            print(root.name)\n",
        "            tree.create_node(root.name, root.name)\n",
        "        if root.is_leaf:\n",
        "            return\n",
        "        self.print_tree_util(root.left_child1, tree, root)\n",
        "        self.print_tree_util(root.left_child2, tree, root)\n",
        "        self.print_tree_util(root.right_child1, tree, root)\n",
        "        self.print_tree_util(root.right_child2, tree, root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/pre-processed_cancer.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7usULr-ZAWf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(686, 35)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:815: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import test\n",
        "\n",
        "\n",
        "dt = MyDecisionTree(min_samples = 686)\n",
        "X = df.drop(['Unnamed: 0', 'Biopsy'], axis=1)\n",
        "Y = df['Biopsy'].to_numpy()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "dt.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Age', 'Schiller') [70, 0] 0\n",
            "leaf 0 2\n",
            "leaf 0 3\n",
            "leaf 1 4\n",
            "leaf 1 1\n",
            "('Age', 'Schiller') [70, 0] 0\n",
            "├── leaf 0 2\n",
            "├── leaf 0 3\n",
            "├── leaf 1 1\n",
            "└── leaf 1 4\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tree = dt.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digraph tree {\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" [label=\"('Age', 'Schiller') [70, 0] 0\", shape=circle]\n",
            "\t\"leaf 0 2\" [label=\"leaf 0 2\", shape=circle]\n",
            "\t\"leaf 0 3\" [label=\"leaf 0 3\", shape=circle]\n",
            "\t\"leaf 1 1\" [label=\"leaf 1 1\", shape=circle]\n",
            "\t\"leaf 1 4\" [label=\"leaf 1 4\", shape=circle]\n",
            "\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 0 2\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 0 3\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 1 4\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 1 1\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "tree.to_graphviz()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0.  18.   4. ...   0.   0.   0.]\n",
            " [  1.  15.   1. ...   0.   0.   0.]\n",
            " [  2.  34.   1. ...   0.   0.   0.]\n",
            " ...\n",
            " [855.  25.   2. ...   0.   1.   0.]\n",
            " [856.  33.   2. ...   0.   0.   0.]\n",
            " [857.  29.   2. ...   0.   0.   0.]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df.to_numpy())\n",
        "cols = df.columns\n",
        "cols_d = {}\n",
        "id=0\n",
        "for col in cols:\n",
        "    cols_d[col] = id\n",
        "    id+=1\n",
        "Y_pred = dt.predict(np.array(X_test.to_numpy()), cols_d)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9302325581395349\n"
          ]
        }
      ],
      "source": [
        "accuracy = (Y_pred == Y_test).sum() / Y_test.shape[0]\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXI_bD3yJ1kG",
        "outputId": "4a68ad85-f1f2-44be-9223-594f7de05da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1437, 64)\n",
            "(360, 64)\n"
          ]
        }
      ],
      "source": [
        "digits = load_digits()\n",
        "X_digits, Y_digits = digits.data, digits.target\n",
        "X_digits = X_digits/255\n",
        "X_digits_train,X_digits_test,Y_digits_train,Y_digits_test=train_test_split(X_digits,Y_digits,test_size=0.2,random_state=42)\n",
        "X_digits_train = pd.DataFrame(X_digits_train)\n",
        "X_digits_test = pd.DataFrame(X_digits_test)\n",
        "\n",
        "print(X_digits_train.shape)\n",
        "print(X_digits_test.shape)\n",
        "\n",
        "# X_iris = pd.DataFrame(X_iris)\n",
        "# print(X_iris.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWfLDmLsJ4Gd",
        "outputId": "9648b4b0-16f4-4012-d524-8c9613c21bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "290 0 0 0\n",
            "71 0 0 0\n",
            "110 0 0 0\n",
            "500 0 0 0\n",
            "236 0 0 0\n",
            "6 0 0 0\n",
            "91 0 0 0\n",
            "94 0 0 0\n",
            "(21, 42) [0.0, 0.058823529411764705] 0\n",
            "leaf 5 1\n",
            "(30, 60) [0.054901960784313725, 0.0] 2\n",
            "leaf 7 4\n",
            "leaf 1 3\n",
            "(28, 36) [0.0, 0.058823529411764705] 5\n",
            "leaf 0 6\n",
            "leaf 9 7\n",
            "leaf 7 8\n",
            "leaf 1 9\n",
            "leaf 4 10\n",
            "leaf 6 11\n",
            "(36, 36) [0.0, 0.0] 12\n",
            "leaf 0 15\n",
            "leaf 1 13\n",
            "leaf 1 14\n",
            "leaf 4 16\n",
            "(21, 42) [0.0, 0.058823529411764705] 0\n",
            "├── (30, 60) [0.054901960784313725, 0.0] 2\n",
            "│   ├── (28, 36) [0.0, 0.058823529411764705] 5\n",
            "│   │   ├── leaf 0 6\n",
            "│   │   ├── leaf 1 9\n",
            "│   │   ├── leaf 7 8\n",
            "│   │   └── leaf 9 7\n",
            "│   ├── leaf 1 3\n",
            "│   ├── leaf 4 10\n",
            "│   └── leaf 7 4\n",
            "├── (36, 36) [0.0, 0.0] 12\n",
            "│   ├── leaf 0 15\n",
            "│   ├── leaf 1 13\n",
            "│   ├── leaf 1 14\n",
            "│   └── leaf 4 16\n",
            "├── leaf 5 1\n",
            "└── leaf 6 11\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt_digits = MyDecisionTree(min_samples=1)\n",
        "dt_digits.fit(X_digits_train, Y_digits_train)\n",
        "tree = dt_digits.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1jbUJe-M5TL",
        "outputId": "32236e20-486d-451e-a4aa-268f3bb19053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "digraph tree {\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" [label=\"('Age', 'Schiller') [70, 0] 0\", shape=circle]\n",
            "\t\"leaf 0 2\" [label=\"leaf 0 2\", shape=circle]\n",
            "\t\"leaf 0 3\" [label=\"leaf 0 3\", shape=circle]\n",
            "\t\"leaf 1 1\" [label=\"leaf 1 1\", shape=circle]\n",
            "\t\"leaf 1 4\" [label=\"leaf 1 4\", shape=circle]\n",
            "\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 0 2\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 0 3\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 1 4\"\n",
            "\t\"('Age', 'Schiller') [70, 0] 0\" -> \"leaf 1 1\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "tree.to_graphviz()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7isM0SHJ74H",
        "outputId": "7bfb7f86-b67f-485d-f9fb-377a7633b5e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4722222222222222\n"
          ]
        }
      ],
      "source": [
        "pred_y_digits = dt_digits.predict(X_digits_test.to_numpy()).squeeze()\n",
        "# print(pred_y_digits)\n",
        "\n",
        "accuracy = (pred_y_digits == Y_digits_test).sum() / Y_digits_test.shape[0]\n",
        "print(accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "970a2a4939579a4c22872227820a264ec023ee5692739211cbaca24386397975"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
