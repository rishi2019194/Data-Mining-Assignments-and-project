{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from treelib import Tree\n",
    "import operator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import t as t_dist\n",
    "from scipy.stats import norm, chi2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, feature=None, threshold=None, left_child=None, right_child=None, is_leaf=False, value=-1, depth=-1):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.depth = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self, min_samples=1, max_depth=-1, max_thresholds=None, min_unique_values=None, num_random_columns=None):\n",
    "        self.root_node = Node('root', depth=0)\n",
    "        self.node_count = 0\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.max_thresholds = max_thresholds\n",
    "        self.min_unique_values = min_unique_values\n",
    "        self.num_random_columns = num_random_columns\n",
    "    \n",
    "    def predict(self, X, cols_d):\n",
    "        \n",
    "        Y_pred = []\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            x_i = X[i]\n",
    "            # print(x_i[0])\n",
    "            curr_node = self.root_node\n",
    "            predicted_y = np.array(self.predict_util(x_i, curr_node, cols_d))\n",
    "            # print(predicted_y)\n",
    "            Y_pred.append(predicted_y)\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def predict_util(self, x, curr_node, cols_d):\n",
    "        \n",
    "        # print(curr_node.feature)\n",
    "        if(curr_node.is_leaf):\n",
    "            return curr_node.value\n",
    "        if x[cols_d[curr_node.feature]] <= curr_node.threshold:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.left_child, cols_d)\n",
    "        else:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.right_child, cols_d)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.fit_util(X, Y, self.root_node)\n",
    "\n",
    "\n",
    "    def fit_util(self, X, Y, current_node):\n",
    "        if np.unique(Y).shape[0] == 1:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        scores = []\n",
    "        num_random_columns = len(X.columns)\n",
    "        if self.num_random_columns is not None:\n",
    "            num_random_columns = self.num_random_columns\n",
    "        random_columns = X.columns.to_numpy()[np.random.permutation(len(X.columns))[:num_random_columns]]\n",
    "        print(random_columns)\n",
    "        for column in random_columns:\n",
    "            X_train = X[column].to_numpy()\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "            clf = LogisticRegression(random_state=0, max_iter=100)\n",
    "            clf.fit(X_train, Y)\n",
    "            score = clf.score(X_train, Y)\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        best_feature = X.columns[np.argmax(scores)]\n",
    "        best_feature_values = np.unique(X[best_feature])\n",
    "        best_feature_values.sort()\n",
    "\n",
    "        partition = self.get_partition(X, Y, best_feature, best_feature_values, current_node.depth)\n",
    "        \n",
    "        if partition == None:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        (X_left, Y_left), (X_right, Y_right), threshold = partition\n",
    "        current_node.threshold = threshold\n",
    "        current_node.feature = best_feature\n",
    "        current_node.name = f'{best_feature} {threshold} {self.node_count}'\n",
    "        self.node_count += 1\n",
    "        current_node.left_child = Node('No name', depth=current_node.depth + 1)\n",
    "        current_node.right_child = Node('No name', depth=current_node.depth + 1)\n",
    "\n",
    "        self.fit_util(X_left, Y_left, current_node.left_child)\n",
    "        self.fit_util(X_right, Y_right, current_node.right_child)\n",
    "\n",
    "        \n",
    "\n",
    "    def do_split(self, X, thresh):\n",
    "        \"\"\"\n",
    "            Split the data at a node based on threshold\n",
    "        \"\"\"\n",
    "\n",
    "        left_child_ids = np.where(X <= thresh, True, False)\n",
    "        right_child_ids = np.where(X > thresh, True, False)\n",
    "        return left_child_ids, right_child_ids\n",
    "    \n",
    "    def find_entropy(self, Y):\n",
    "        probs = []\n",
    "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
    "        sort_indices = np.argsort(possible_classes)\n",
    "        possible_classes = possible_classes[sort_indices]\n",
    "        counts = counts[sort_indices]\n",
    "        \n",
    "        for class_label, count in zip(possible_classes, counts):\n",
    "            probs.append(count/Y.shape[0])\n",
    "        \n",
    "        entropy = 0\n",
    "        for prob in probs:\n",
    "            entropy -= prob*np.log2(prob)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def get_partition(self, X, Y, feature, thresholds, current_node_depth):\n",
    "        '''\n",
    "            This function should return left and right\n",
    "            partitions according to appropritate\n",
    "            partitioning algorithm. Return None if all\n",
    "            data has same label\n",
    "        '''\n",
    "        \n",
    "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
    "        if(len(Y) < self.min_samples):\n",
    "            return None\n",
    "        if(current_node_depth == self.max_depth):\n",
    "            return None\n",
    "        \n",
    "        best_info_gain = -float('inf')\n",
    "        best_thresh = thresholds[0]      \n",
    "        threshold_cnt = len(thresholds)  \n",
    "        if self.max_thresholds is not None:\n",
    "            threshold_cnt = self.max_thresholds\n",
    "        min_unique_values = len(thresholds)\n",
    "\n",
    "        if self.min_unique_values is not None:\n",
    "            min_unique_values = self.min_unique_values\n",
    "        \n",
    "        print(\"Now thresholding!\")\n",
    "        for thresh in (thresholds[:-1] if len(thresholds) <= min_unique_values else thresholds[:-1:len(thresholds) // threshold_cnt]):\n",
    "\n",
    "            left_child_ids, right_child_ids = self.do_split(X[feature].to_numpy(), thresh)\n",
    "\n",
    "            parent_pts = X.shape[0]\n",
    "            left_child_pts = len(left_child_ids)\n",
    "            right_child_pts = len(right_child_ids)\n",
    "\n",
    "            info_gain = self.find_entropy(Y) - (left_child_pts / parent_pts) * self.find_entropy(Y[left_child_ids]) - (right_child_pts / parent_pts) * self.find_entropy(Y[right_child_ids])\n",
    "\n",
    "            if(info_gain > best_info_gain):\n",
    "\n",
    "                best_info_gain = info_gain\n",
    "                best_thresh = thresh\n",
    "        \n",
    "        # partition according to best threshold\n",
    "        best_left_ids, best_right_ids = self.do_split(X[feature].to_numpy(), best_thresh)\n",
    "        # print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "        if(len(Y[best_left_ids]) == 0 or len(Y[best_right_ids]) == 0):\n",
    "            # print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "            return None\n",
    "        return (X[best_left_ids], Y[best_left_ids]), (X[best_right_ids], Y[best_right_ids]), best_thresh\n",
    "    \n",
    "    def print_tree(self):\n",
    "        tree = Tree()\n",
    "        self.print_tree_util(self.root_node, tree)\n",
    "        tree.show()\n",
    "        return tree\n",
    "\n",
    "    def print_tree_util(self, root, tree, parent=None):\n",
    "        if parent is not None:\n",
    "            tree.create_node(root.name, root.name, parent=parent.name)\n",
    "        else:\n",
    "            tree.create_node(root.name, root.name)\n",
    "        if root.is_leaf:\n",
    "            return\n",
    "        self.print_tree_util(root.left_child, tree, root)\n",
    "        self.print_tree_util(root.right_child, tree, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2:\n",
    "    def __init__(self, name, feature=None, threshold=None, left_child1=None, left_child2=None, right_child1=None, right_child2=None, is_leaf=False, value=-1, depth=-1):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child1 = left_child1\n",
    "        self.left_child2 = left_child2\n",
    "        self.right_child1 = right_child1\n",
    "        self.right_child2 = right_child2\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.depth = depth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree2:\n",
    "    def __init__(self, min_samples=1, max_depth=-1, max_thresholds=None, min_unique_values=None, num_random_columns=None):\n",
    "        self.root_node = Node2('root', depth=0)\n",
    "        self.node_count = 0\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.max_thresholds = max_thresholds\n",
    "        self.min_unique_values = min_unique_values\n",
    "        self.num_random_columns = num_random_columns\n",
    "    \n",
    "    def predict(self, X, cols_d):\n",
    "        \n",
    "        Y_pred = []\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            x_i = X[i]\n",
    "            # print(x_i[0])\n",
    "            curr_node = self.root_node\n",
    "            predicted_y = np.array(self.predict_util(x_i, curr_node, cols_d))\n",
    "            # print(predicted_y)\n",
    "            Y_pred.append(predicted_y)\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def predict_util(self, x, curr_node, cols_d):\n",
    "        \n",
    "        if(curr_node.is_leaf):\n",
    "            return curr_node.value\n",
    "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.left_child1, cols_d)\n",
    "\n",
    "        if x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.left_child2, cols_d)\n",
    "\n",
    "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.right_child1, cols_d)\n",
    "\n",
    "        elif x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.right_child2, cols_d)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.fit_util(X, Y, self.root_node)\n",
    "\n",
    "\n",
    "    def fit_util(self, X, Y, current_node):\n",
    "        if np.unique(Y).shape[0] == 1:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        scores = {}\n",
    "        num_random_columns = len(X.columns)\n",
    "        if self.num_random_columns is not None:\n",
    "            num_random_columns = self.num_random_columns\n",
    "        random_columns = X.columns.to_numpy()[np.random.permutation(len(X.columns))[:num_random_columns]]\n",
    "        \n",
    "        for column1 in random_columns:\n",
    "            for column2 in random_columns:\n",
    "                column = [column1, column2]\n",
    "                X_train = X[column].to_numpy()\n",
    "                X_train = X_train.reshape(X_train.shape[0], 2)\n",
    "                clf = LogisticRegression(random_state=0)\n",
    "                clf.fit(X_train, Y)\n",
    "                score = clf.score(X_train, Y)\n",
    "                scores[(column1, column2)] = score\n",
    "            \n",
    "\n",
    "        scores_sorted = dict( sorted(scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "        best_feature_set = list(scores_sorted.keys())[0]\n",
    "        best_feature1_values = np.unique(X[best_feature_set[0]])\n",
    "        best_feature2_values = np.unique(X[best_feature_set[1]])\n",
    "\n",
    "        best_feature1_values.sort()\n",
    "        best_feature2_values.sort()\n",
    "\n",
    "        partition = self.get_partition(X, Y, best_feature_set[0], best_feature_set[1], best_feature1_values, best_feature2_values, current_node.depth)\n",
    "        \n",
    "        if partition == None:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        (X_left1, Y_left1), (X_left2, Y_left2), (X_right1, Y_right1), (X_right2, Y_right2), threshold1, threshold2 = partition\n",
    "\n",
    "        threshold = [threshold1, threshold2]\n",
    "        # print(\"Thresholds: \",threshold)\n",
    "        current_node.threshold = threshold\n",
    "        current_node.feature = best_feature_set\n",
    "        current_node.name = f'{best_feature_set} {threshold} {self.node_count}'\n",
    "        self.node_count += 1\n",
    "        current_node.left_child1 = Node2('unnamed', depth=current_node.depth + 1)\n",
    "        current_node.left_child2 = Node2('unnamed', depth=current_node.depth + 1)\n",
    "        current_node.right_child1 = Node2('unnamed', depth=current_node.depth + 1)\n",
    "        current_node.right_child2 = Node2('unnamed', depth=current_node.depth + 1)\n",
    "\n",
    "        unq, counts = np.unique(Y, return_counts=True)\n",
    "        max_freq_idx = np.argmax(counts).flatten()\n",
    "        if(X_left1.shape[0] == 0):\n",
    "            current_node.left_child1.is_leaf = True\n",
    "            current_node.left_child1.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.left_child1.name = f'leaf {current_node.left_child1.value} {self.node_count}'\n",
    "            self.node_count+=1 \n",
    "            # return\n",
    "        \n",
    "        if(X_left2.shape[0] == 0):\n",
    "            current_node.left_child2.is_leaf = True\n",
    "            current_node.left_child2.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.left_child2.name = f'leaf {current_node.left_child2.value} {self.node_count}'\n",
    "            self.node_count+=1 \n",
    "            # return\n",
    "        \n",
    "        if(X_right1.shape[0] == 0):\n",
    "            current_node.right_child1.is_leaf = True\n",
    "            current_node.right_child1.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.right_child1.name = f'leaf {current_node.right_child1.value} {self.node_count}'\n",
    "            self.node_count+=1   \n",
    "            # return     \n",
    "        \n",
    "        if(X_right2.shape[0] == 0):\n",
    "            current_node.right_child2.is_leaf = True\n",
    "            current_node.right_child2.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.right_child2.name = f'leaf {current_node.right_child2.value} {self.node_count}'\n",
    "            self.node_count+=1  \n",
    "            # return                  \n",
    "          \n",
    "        if(X_left1.shape[0] != 0):\n",
    "            self.fit_util(X_left1, Y_left1, current_node.left_child1)\n",
    "        \n",
    "        if(X_left2.shape[0] != 0):\n",
    "            self.fit_util(X_left2, Y_left2, current_node.left_child2)\n",
    "        \n",
    "        if(X_right1.shape[0] != 0):\n",
    "            self.fit_util(X_right1, Y_right1, current_node.right_child1)\n",
    "        \n",
    "        if(X_right2.shape[0] != 0):\n",
    "            self.fit_util(X_right2, Y_right2, current_node.right_child2)\n",
    "\n",
    "\n",
    "    def do_split(self, X, thresh):\n",
    "        \"\"\"\n",
    "            Split the data at a node based on threshold\n",
    "        \"\"\"\n",
    "\n",
    "        left_child_ids = np.where(X <= thresh, True, False)\n",
    "        right_child_ids = np.where(X > thresh, True, False)\n",
    "        return left_child_ids, right_child_ids\n",
    "\n",
    "    def do_split_final(self, X1, X2, thresh1, thresh2):\n",
    "\n",
    "        \"\"\"\n",
    "            Split according to the best thresholds for the 2 features\n",
    "        \"\"\"   \n",
    "\n",
    "        left1_ids = np.where(np.logical_and(X1 <= thresh1, X2 <= thresh2), True, False)\n",
    "        left2_ids = np.where(np.logical_and(X1 > thresh1, X2 <= thresh2), True, False)\n",
    "        right1_ids = np.where(np.logical_and(X1 <= thresh1, X2 > thresh2), True, False)\n",
    "        right2_ids = np.where(np.logical_and(X1 > thresh1, X2 > thresh2), True, False)\n",
    "\n",
    "        return left1_ids, left2_ids, right1_ids, right2_ids\n",
    "\n",
    "    def find_entropy(self, Y):\n",
    "        probs = []\n",
    "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
    "        sort_indices = np.argsort(possible_classes)\n",
    "        possible_classes = possible_classes[sort_indices]\n",
    "        counts = counts[sort_indices]\n",
    "        \n",
    "        for class_label, count in zip(possible_classes, counts):\n",
    "            probs.append(count/Y.shape[0])\n",
    "        \n",
    "        entropy = 0\n",
    "        for prob in probs:\n",
    "            entropy -= prob*np.log2(prob)\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def find_best_thresh_info_gain(self, thresholds1, thresholds2, X, Y, feature1, feature2):\n",
    "        \"\"\"\n",
    "            This function finds the best threshold and info gain for a given feature\n",
    "        \"\"\"\n",
    "        best_info_gain = -float('inf')\n",
    "        best_thresh1 = thresholds1[0]   \n",
    "        best_thresh2 = thresholds2[0]     \n",
    "        threshold_cnt_1 = len(thresholds1)\n",
    "        threshold_cnt_2  = len(thresholds2)\n",
    "        if self.max_thresholds is not None:\n",
    "            threshold_cnt_1, threshold_cnt_2 = self.max_thresholds, self.max_thresholds\n",
    "        min_unique_values_1 = len(thresholds1)\n",
    "        min_unique_values_2 = len(thresholds2)\n",
    "\n",
    "        if self.min_unique_values is not None:\n",
    "            min_unique_values_1, min_unique_values_2 = self.min_unique_values, self.min_unique_values\n",
    "        \n",
    "        print(\"Now thresholding!\")\n",
    "        for thresh1 in (thresholds1[:-1] if len(thresholds1) <= min_unique_values_1 else thresholds1[:-1:len(thresholds1) // threshold_cnt_1]):\n",
    "            for thresh2 in (thresholds2[:-1] if len(thresholds2) <= min_unique_values_2 else thresholds2[:-1:len(thresholds2) // threshold_cnt_2]):\n",
    "                left_child1_ids, left_child2_ids,  right_child1_ids, right_child2_ids = self.do_split_final(X[feature1].to_numpy(),X[feature2].to_numpy(), thresh1, thresh2)\n",
    "\n",
    "                parent_pts = X.shape[0]\n",
    "                left_child1_pts = len(left_child1_ids)\n",
    "                left_child2_pts = len(left_child2_ids)\n",
    "                right_child1_pts = len(right_child1_ids)\n",
    "                right_child2_pts = len(right_child2_ids)\n",
    "\n",
    "                info_gain = self.find_entropy(Y) - (left_child1_pts / parent_pts) * self.find_entropy(Y[left_child1_ids]) - (left_child2_pts / parent_pts) * self.find_entropy(Y[left_child2_ids]) - (right_child1_pts / parent_pts) * self.find_entropy(Y[right_child1_ids]) - (right_child2_pts / parent_pts) * self.find_entropy(Y[right_child2_ids])\n",
    "                \n",
    "                if(info_gain > best_info_gain):\n",
    "\n",
    "                    best_info_gain = info_gain\n",
    "                    best_thresh1 = thresh1\n",
    "                    best_thresh2 = thresh2\n",
    "\n",
    "        \n",
    "        return best_thresh1, best_thresh2, best_info_gain\n",
    "\n",
    "    def get_partition(self, X, Y, feature1, feature2, thresholds1, thresholds2, current_node_depth):\n",
    "        '''\n",
    "            This function should return left and right\n",
    "            partitions according to appropritate\n",
    "            partitioning algorithm. Return None if all\n",
    "            data has same label\n",
    "        '''\n",
    "        \n",
    "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
    "        if(len(Y) < self.min_samples):\n",
    "            return None\n",
    "        if(current_node_depth == self.max_depth):\n",
    "            return None\n",
    "        \n",
    "        best_thresh1, best_thresh2, best_info_gain = self.find_best_thresh_info_gain(thresholds1, thresholds2, X, Y, feature1, feature2)\n",
    "\n",
    "        # partition according to best threshold\n",
    "        best_left_ids1, best_left_ids2, best_right_ids1, best_right_ids2 = self.do_split_final(X[feature1].to_numpy(), X[feature2].to_numpy(), best_thresh1, best_thresh2)\n",
    "\n",
    "        # print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
    "\n",
    "        count_0 = 0\n",
    "        if(len(Y[best_left_ids1]) == 0):\n",
    "            count_0 += 1\n",
    "        if(len(Y[best_left_ids2]) == 0):\n",
    "            count_0 += 1\n",
    "        if(len(Y[best_right_ids1]) == 0):\n",
    "            count_0 += 1\n",
    "        if(len(Y[best_right_ids2]) == 0):\n",
    "            count_0 += 1\n",
    "\n",
    "        if(count_0 == 3):\n",
    "            print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
    "            return None\n",
    "\n",
    "        return (X[best_left_ids1], Y[best_left_ids1]), (X[best_left_ids2], Y[best_left_ids2]), (X[best_right_ids1], Y[best_right_ids1]),(X[best_right_ids2], Y[best_right_ids2]), best_thresh1, best_thresh2    \n",
    "    \n",
    "    def print_tree(self):\n",
    "        tree = Tree()\n",
    "        self.print_tree_util(self.root_node, tree)\n",
    "        tree.show()\n",
    "        return tree\n",
    "\n",
    "    def print_tree_util(self, root, tree, parent=None):\n",
    "        if parent is not None:\n",
    "            print(root.name)\n",
    "            tree.create_node(root.name, root.name, parent=parent.name)\n",
    "        else:\n",
    "            print(root.name)\n",
    "            tree.create_node(root.name, root.name)\n",
    "        if root.is_leaf:\n",
    "            return\n",
    "        self.print_tree_util(root.left_child1, tree, root)\n",
    "        self.print_tree_util(root.left_child2, tree, root)\n",
    "        self.print_tree_util(root.right_child1, tree, root)\n",
    "        self.print_tree_util(root.right_child2, tree, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def paired_t_test(p):\n",
    "#     p_hat = np.mean(p)\n",
    "#     n = len(p)\n",
    "#     den = np.sqrt(sum([(diff - p_hat)**2 for diff in p]) / (n - 1))\n",
    "#     t = (p_hat * (n**(1/2))) / den\n",
    "    \n",
    "#     p_value = t_dist.sf(t, n-1)*2\n",
    "    \n",
    "#     return t, p_value\n",
    "\n",
    "# def z_test(acc1, acc2, n):\n",
    "\n",
    "#     z, p = proportion_difference(acc1, acc2, n_1 = n)\n",
    "#     return z,p\n",
    "\n",
    "# def mcnamer_test(Y_test, Y_pred1, Y_pred2):\n",
    "#     b = sum(np.logical_and((Y_pred2 != Y_test), (Y_pred1 == Y_test)))\n",
    "#     c = sum(np.logical_and((Y_pred1 != Y_test), (Y_pred2 == Y_test)))\n",
    "\n",
    "#     chi_2 = ((np.abs(b-c)-1)**2)/(b+c)\n",
    "#     p = chi2.sf(chi_2, 1)\n",
    "\n",
    "#     return chi_2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cancer = pd.read_csv('./data/final_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 30)\n",
      "(array([0, 1], dtype=int64), array([642,  44], dtype=int64))\n",
      "(array([0, 1], dtype=int64), array([161,  11], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X_cancer = df_cancer.drop(['Unnamed: 0', 'Biopsy'], axis=1)\n",
    "Y_cancer = df_cancer['Biopsy'].to_numpy()\n",
    "X_train_cancer, X_test_cancer, Y_train_cancer, Y_test_cancer = train_test_split(X_cancer, Y_cancer, test_size=0.2, random_state = 42, stratify=Y_cancer)\n",
    "print(X_train_cancer.shape)\n",
    "print(np.unique(Y_train_cancer, return_counts=True))\n",
    "print(np.unique(Y_test_cancer, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cancer = X_cancer.columns\n",
    "cols_d_cancer = {}\n",
    "id=0\n",
    "for col in cols_cancer:\n",
    "    cols_d_cancer[col] = id\n",
    "    id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['STDs:Hepatitis B']\n",
      "Now thresholding!\n",
      "['Age']\n",
      "Now thresholding!\n",
      "['STDs:pelvic inflammatory disease']\n",
      "Now thresholding!\n",
      "['Num of pregnancies']\n",
      "Now thresholding!\n",
      "['STDs: Number of diagnosis']\n",
      "Now thresholding!\n",
      "['STDs:pelvic inflammatory disease']\n",
      "One-feature split accuracy:  0.936046511627907\n",
      "One-feature split Precision:  0.0\n",
      "One-feature split Recall:  0.0\n",
      "One-feature split F1-Score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "dt_cancer1 = MyDecisionTree(max_depth=5, num_random_columns=1)\n",
    "dt_cancer1.fit(X_train_cancer, Y_train_cancer)\n",
    "Y_pred1_cancer = dt_cancer1.predict(np.array(X_test_cancer.to_numpy()), cols_d_cancer)\n",
    "accuracy1 = accuracy_score(Y_pred1_cancer, Y_test_cancer)\n",
    "precision1 = precision_score(Y_pred1_cancer, Y_test_cancer)\n",
    "recall1 = recall_score(Y_pred1_cancer, Y_test_cancer)\n",
    "f1 = f1_score(Y_pred1_cancer, Y_test_cancer)\n",
    "print(\"One-feature split accuracy: \", accuracy1)\n",
    "print(\"One-feature split Precision: \", precision1)\n",
    "print(\"One-feature split Recall: \", recall1)\n",
    "print(\"One-feature split F1-Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 70 0\n",
      "├── leaf 0 1\n",
      "└── leaf 0 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = dt_cancer1.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dt_cancer1, open(\"Results/Data1/1_Way/Models_Saved/Model.pkl\", 'wb'))\n",
    "metrics_array = np.array([accuracy1, precision1, recall1, f1])\n",
    "\n",
    "with open('./Results/Data1/1_Way/Metrics/metrics.npy', 'wb') as f:\n",
    "    np.save(f, metrics_array)\n",
    "\n",
    "with open('./Results/Data1/1_Way/Y_Pred/Pred.npy', 'wb') as f:\n",
    "    np.save(f, Y_pred1_cancer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 70 0\n",
      "├── Age 52 1\n",
      "│   ├── Age 51 2\n",
      "│   │   ├── Age 50 3\n",
      "│   │   │   ├── Age 49 4\n",
      "│   │   │   │   ├── leaf 0 5\n",
      "│   │   │   │   └── leaf 0 6\n",
      "│   │   │   └── leaf 1 7\n",
      "│   │   └── leaf 0 8\n",
      "│   └── leaf 0 9\n",
      "└── leaf 0 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pickled_model = pickle.load(open(\"Results/Data1/1_Way/Models_Saved/Model.pkl\", 'rb'))\n",
    "Y_ = pickled_model.predict(np.array(X_test_cancer.to_numpy()), cols_d_cancer)\n",
    "tree = pickled_model.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m Y_train, Y_test \u001b[39m=\u001b[39m Y_cancer[train_index], Y_cancer[test_index]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dt1_cancer \u001b[39m=\u001b[39m MyDecisionTree(min_samples\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m dt1_cancer\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m Y_pred1_cancer \u001b[39m=\u001b[39m dt1_cancer\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray(X_test\u001b[39m.\u001b[39mto_numpy()), cols_d_cancer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m accuracy1 \u001b[39m=\u001b[39m accuracy_score(Y_pred1_cancer, Y_test)\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, Y):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X, Y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_node)\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39mleft_child)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39;49mright_child)\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m current_node\u001b[39m.\u001b[39mleft_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39;49mleft_child)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39mright_child)\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m current_node\u001b[39m.\u001b[39mleft_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39;49mleft_child)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39mright_child)\n",
      "    \u001b[1;31m[... skipping similar frames: MyDecisionTree.fit_util at line 89 (5 times)]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39mleft_child)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39;49mright_child)\n",
      "    \u001b[1;31m[... skipping similar frames: MyDecisionTree.fit_util at line 90 (3 times)]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39mleft_child)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39;49mright_child)\n",
      "    \u001b[1;31m[... skipping similar frames: MyDecisionTree.fit_util at line 89 (5 times)]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m current_node\u001b[39m.\u001b[39mleft_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m current_node\u001b[39m.\u001b[39mright_child \u001b[39m=\u001b[39m Node(\u001b[39m'\u001b[39m\u001b[39mNo name\u001b[39m\u001b[39m'\u001b[39m, depth\u001b[39m=\u001b[39mcurrent_node\u001b[39m.\u001b[39mdepth \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_util(X_left, Y_left, current_node\u001b[39m.\u001b[39;49mleft_child)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_util(X_right, Y_right, current_node\u001b[39m.\u001b[39mright_child)\n",
      "\u001b[1;32mc:\\Users\\DELL\\OneDrive\\Documents\\GitHub\\DMG-Group12\\final_file.ipynb Cell 13\u001b[0m in \u001b[0;36mMyDecisionTree.fit_util\u001b[1;34m(self, X, Y, current_node)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     clf \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     clf\u001b[39m.\u001b[39mfit(X_train, Y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     score \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mscore(X_train, Y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(score)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DELL/OneDrive/Documents/GitHub/DMG-Group12/final_file.ipynb#X15sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(scores)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:651\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 651\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m---> 86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred)\n\u001b[0;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\multiclass.py:327\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    324\u001b[0m     _assert_all_finite(y)\n\u001b[0;32m    325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m--> 327\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(y)) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix  \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n\u001b[0;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\arraysetops.py:348\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    346\u001b[0m     mask[aux_firstnan \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m     mask[\u001b[39m1\u001b[39m:] \u001b[39m=\u001b[39m aux[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m aux[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    350\u001b[0m ret \u001b[39m=\u001b[39m (aux[mask],)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m return_index:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc_scores1 = []\n",
    "precision_scores1 = []\n",
    "recall_scores1 = []\n",
    "f1_scores1 = []\n",
    "strtfdKFold = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in strtfdKFold.split(X_cancer, Y_cancer):\n",
    "    X_train, X_test = X_cancer.iloc[train_index, :], X_cancer.iloc[test_index, :]\n",
    "    Y_train, Y_test = Y_cancer[train_index], Y_cancer[test_index]\n",
    "\n",
    "    dt1_cancer = MyDecisionTree(min_samples=1,  )\n",
    "    dt1_cancer.fit(X_train, Y_train)\n",
    "    Y_pred1_cancer = dt1_cancer.predict(np.array(X_test.to_numpy()), cols_d_cancer)\n",
    "\n",
    "    accuracy1 = accuracy_score(Y_pred1_cancer, Y_test)\n",
    "    precision1 = precision_score(Y_pred1_cancer, Y_test)\n",
    "    recall1 = recall_score(Y_pred1_cancer, Y_test)\n",
    "    f1 = f1_score(Y_pred1_cancer, Y_test)\n",
    "\n",
    "    acc_scores1.append(accuracy1)\n",
    "    precision1.append(precision1)\n",
    "    recall1.append(recall1)\n",
    "    f1_scores1.append(f1)\n",
    "\n",
    "    print(\"----------\")\n",
    "    print(\"Accuracy1: \", accuracy1)\n",
    "    print(\"Precision1: \", precision1)\n",
    "    print(\"Recall1: \", recall1)\n",
    "    print(\"F1-score: \", f1)\n",
    "    print(\"----------\")\n",
    "\n",
    "\n",
    "with open(\"Results/Data1/1_Way/K_Folds/Accuracy/acc.npy\",'wb') as f:\n",
    "    np.save(f, np.array(acc_scores1))\n",
    "\n",
    "with open(\"Results/Data1/1_Way/K_Folds/Precision/precision.npy\", 'wb') as f:\n",
    "    np.save(f, np.array(precision1))\n",
    "\n",
    "with open(\"Results/Data1/1_Way/K_Folds/Recall/recall.npy\", 'wb') as f:\n",
    "    np.save(f, np.array(recall1))\n",
    "\n",
    "with open(\"Results/Data1/1_Way/K_Folds/F1_Score/f1.npy\", 'wb') as f:\n",
    "    np.save(f, np.array(f1_scores1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "596 0 0 0\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "28 0 0 0\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "10 0 0 0\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "Now thresholding!\n",
      "12 0 0 0\n"
     ]
    }
   ],
   "source": [
    "dt_cancer2 = MyDecisionTree2(min_samples=1, num_random_columns=30)\n",
    "dt_cancer2.fit(X_train_cancer, Y_train_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two-features split accuracy:  0.9302325581395349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25000000000000006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred2_cancer = dt_cancer2.predict(np.array(X_test_cancer.to_numpy()), cols_d_cancer)\n",
    "accuracy2 = accuracy_score(Y_pred2_cancer, Y_test_cancer)\n",
    "print(\"two-features split accuracy: \", accuracy2)\n",
    "f1_score(Y_pred2_cancer, Y_test_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8200629894731226 0.04782506579017487\n"
     ]
    }
   ],
   "source": [
    "t, p_value = paired_t_test(acc_scores_diff)\n",
    "print(t, p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "970a2a4939579a4c22872227820a264ec023ee5692739211cbaca24386397975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
