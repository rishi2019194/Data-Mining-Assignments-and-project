{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import OneClassSVM\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_prediction(X_train, Y_train, X_test, Y_test):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(5,), \n",
    "                    activation='logistic', \n",
    "                    alpha=1e-4,\n",
    "                    solver='sgd', \n",
    "                    tol=1e-4,\n",
    "                    random_state=1,\n",
    "                    learning_rate_init=.03, \n",
    "                    verbose=True)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    return classification_report(Y_test, Y_pred)\n",
    "\n",
    "def get_tsne(X):\n",
    "    X_embedded = TSNE(n_components = 2, learning_rate='auto', init='random').fit_transform(X)\n",
    "    return X_embedded\n",
    "\n",
    "\n",
    "def get_plot(X, Y):\n",
    "    data_embedded_combined = pd.DataFrame(data=np.c_[X, Y], columns=['tsne-one-d', 'tsne-two-d'] + ['target'])\n",
    "    sns.lmplot(data=data_embedded_combined, x='tsne-one-d', y='tsne-two-d', hue='target', fit_reg = False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  target  \n",
       "0           0.0     0.0  \n",
       "1           0.0     1.0  \n",
       "2           0.0     2.0  \n",
       "3           0.0     3.0  \n",
       "4           0.0     4.0  \n",
       "...         ...     ...  \n",
       "1792        0.0     9.0  \n",
       "1793        0.0     0.0  \n",
       "1794        0.0     8.0  \n",
       "1795        0.0     9.0  \n",
       "1796        0.0     8.0  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/digits.csv\")\n",
    "# print(data.columns)\n",
    "data.drop(['Unnamed: 0'], inplace= True, axis= 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([178, 182, 177, 183, 181, 182, 181, 179, 174, 180], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['target'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {'ad.': 1,'nonad.': 0}\n",
    "  \n",
    "# data['class'] = [labels[item] for item in data['class']]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(['target'], axis = 1)\n",
    "y = data['target']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.35394094\n",
      "Iteration 2, loss = 2.22873221\n",
      "Iteration 3, loss = 2.14173916\n",
      "Iteration 4, loss = 2.06343938\n",
      "Iteration 5, loss = 1.97984047\n",
      "Iteration 6, loss = 1.88956681\n",
      "Iteration 7, loss = 1.80241276\n",
      "Iteration 8, loss = 1.71803605\n",
      "Iteration 9, loss = 1.63667256\n",
      "Iteration 10, loss = 1.55825642\n",
      "Iteration 11, loss = 1.48650718\n",
      "Iteration 12, loss = 1.41272760\n",
      "Iteration 13, loss = 1.34630016\n",
      "Iteration 14, loss = 1.28364787\n",
      "Iteration 15, loss = 1.22261510\n",
      "Iteration 16, loss = 1.16796483\n",
      "Iteration 17, loss = 1.11325222\n",
      "Iteration 18, loss = 1.06359202\n",
      "Iteration 19, loss = 1.01694701\n",
      "Iteration 20, loss = 0.97919718\n",
      "Iteration 21, loss = 0.94415936\n",
      "Iteration 22, loss = 0.89910894\n",
      "Iteration 23, loss = 0.86754921\n",
      "Iteration 24, loss = 0.83515688\n",
      "Iteration 25, loss = 0.81269557\n",
      "Iteration 26, loss = 0.78506106\n",
      "Iteration 27, loss = 0.75796719\n",
      "Iteration 28, loss = 0.74480566\n",
      "Iteration 29, loss = 0.71461143\n",
      "Iteration 30, loss = 0.70176307\n",
      "Iteration 31, loss = 0.67849848\n",
      "Iteration 32, loss = 0.65668769\n",
      "Iteration 33, loss = 0.63849083\n",
      "Iteration 34, loss = 0.62213051\n",
      "Iteration 35, loss = 0.60833187\n",
      "Iteration 36, loss = 0.59645527\n",
      "Iteration 37, loss = 0.58007523\n",
      "Iteration 38, loss = 0.57232259\n",
      "Iteration 39, loss = 0.56170361\n",
      "Iteration 40, loss = 0.54934900\n",
      "Iteration 41, loss = 0.53314442\n",
      "Iteration 42, loss = 0.53076221\n",
      "Iteration 43, loss = 0.51891182\n",
      "Iteration 44, loss = 0.50550162\n",
      "Iteration 45, loss = 0.49845739\n",
      "Iteration 46, loss = 0.48961587\n",
      "Iteration 47, loss = 0.47567788\n",
      "Iteration 48, loss = 0.47453489\n",
      "Iteration 49, loss = 0.46493783\n",
      "Iteration 50, loss = 0.46040024\n",
      "Iteration 51, loss = 0.45554302\n",
      "Iteration 52, loss = 0.44242847\n",
      "Iteration 53, loss = 0.44092361\n",
      "Iteration 54, loss = 0.43918817\n",
      "Iteration 55, loss = 0.42560546\n",
      "Iteration 56, loss = 0.41875900\n",
      "Iteration 57, loss = 0.41825939\n",
      "Iteration 58, loss = 0.41239831\n",
      "Iteration 59, loss = 0.40294811\n",
      "Iteration 60, loss = 0.40594737\n",
      "Iteration 61, loss = 0.40227846\n",
      "Iteration 62, loss = 0.39090382\n",
      "Iteration 63, loss = 0.39553630\n",
      "Iteration 64, loss = 0.39126239\n",
      "Iteration 65, loss = 0.39352742\n",
      "Iteration 66, loss = 0.37858613\n",
      "Iteration 67, loss = 0.37350380\n",
      "Iteration 68, loss = 0.36753724\n",
      "Iteration 69, loss = 0.36056701\n",
      "Iteration 70, loss = 0.35800319\n",
      "Iteration 71, loss = 0.36484267\n",
      "Iteration 72, loss = 0.34945603\n",
      "Iteration 73, loss = 0.35386635\n",
      "Iteration 74, loss = 0.35271398\n",
      "Iteration 75, loss = 0.35634164\n",
      "Iteration 76, loss = 0.34717063\n",
      "Iteration 77, loss = 0.34179927\n",
      "Iteration 78, loss = 0.33221509\n",
      "Iteration 79, loss = 0.32919770\n",
      "Iteration 80, loss = 0.33103188\n",
      "Iteration 81, loss = 0.33616127\n",
      "Iteration 82, loss = 0.34712853\n",
      "Iteration 83, loss = 0.33375863\n",
      "Iteration 84, loss = 0.32374728\n",
      "Iteration 85, loss = 0.32749975\n",
      "Iteration 86, loss = 0.33453477\n",
      "Iteration 87, loss = 0.32498606\n",
      "Iteration 88, loss = 0.31716741\n",
      "Iteration 89, loss = 0.31877497\n",
      "Iteration 90, loss = 0.30971509\n",
      "Iteration 91, loss = 0.30716068\n",
      "Iteration 92, loss = 0.30510588\n",
      "Iteration 93, loss = 0.29950695\n",
      "Iteration 94, loss = 0.29935370\n",
      "Iteration 95, loss = 0.31449665\n",
      "Iteration 96, loss = 0.30278388\n",
      "Iteration 97, loss = 0.29786727\n",
      "Iteration 98, loss = 0.29258499\n",
      "Iteration 99, loss = 0.29663222\n",
      "Iteration 100, loss = 0.29166180\n",
      "Iteration 101, loss = 0.29527083\n",
      "Iteration 102, loss = 0.30125119\n",
      "Iteration 103, loss = 0.28581475\n",
      "Iteration 104, loss = 0.28511742\n",
      "Iteration 105, loss = 0.28224538\n",
      "Iteration 106, loss = 0.28139991\n",
      "Iteration 107, loss = 0.27481457\n",
      "Iteration 108, loss = 0.27924166\n",
      "Iteration 109, loss = 0.27887064\n",
      "Iteration 110, loss = 0.31819960\n",
      "Iteration 111, loss = 0.27176641\n",
      "Iteration 112, loss = 0.27789322\n",
      "Iteration 113, loss = 0.27487392\n",
      "Iteration 114, loss = 0.27304904\n",
      "Iteration 115, loss = 0.27705464\n",
      "Iteration 116, loss = 0.27419687\n",
      "Iteration 117, loss = 0.27616573\n",
      "Iteration 118, loss = 0.26046798\n",
      "Iteration 119, loss = 0.25567418\n",
      "Iteration 120, loss = 0.26019896\n",
      "Iteration 121, loss = 0.25919374\n",
      "Iteration 122, loss = 0.26160724\n",
      "Iteration 123, loss = 0.25999945\n",
      "Iteration 124, loss = 0.25683152\n",
      "Iteration 125, loss = 0.25468797\n",
      "Iteration 126, loss = 0.26379884\n",
      "Iteration 127, loss = 0.25510694\n",
      "Iteration 128, loss = 0.24740932\n",
      "Iteration 129, loss = 0.25352196\n",
      "Iteration 130, loss = 0.25166435\n",
      "Iteration 131, loss = 0.24489798\n",
      "Iteration 132, loss = 0.24195734\n",
      "Iteration 133, loss = 0.24637834\n",
      "Iteration 134, loss = 0.23981560\n",
      "Iteration 135, loss = 0.24487413\n",
      "Iteration 136, loss = 0.25258337\n",
      "Iteration 137, loss = 0.29617225\n",
      "Iteration 138, loss = 0.25627992\n",
      "Iteration 139, loss = 0.25837137\n",
      "Iteration 140, loss = 0.24364317\n",
      "Iteration 141, loss = 0.24251528\n",
      "Iteration 142, loss = 0.23942293\n",
      "Iteration 143, loss = 0.23461970\n",
      "Iteration 144, loss = 0.23652579\n",
      "Iteration 145, loss = 0.23220600\n",
      "Iteration 146, loss = 0.23536968\n",
      "Iteration 147, loss = 0.25034845\n",
      "Iteration 148, loss = 0.23392613\n",
      "Iteration 149, loss = 0.23542970\n",
      "Iteration 150, loss = 0.22894682\n",
      "Iteration 151, loss = 0.23270144\n",
      "Iteration 152, loss = 0.22912740\n",
      "Iteration 153, loss = 0.25298892\n",
      "Iteration 154, loss = 0.23601499\n",
      "Iteration 155, loss = 0.25656757\n",
      "Iteration 156, loss = 0.23330506\n",
      "Iteration 157, loss = 0.23869858\n",
      "Iteration 158, loss = 0.22962332\n",
      "Iteration 159, loss = 0.22555538\n",
      "Iteration 160, loss = 0.23120461\n",
      "Iteration 161, loss = 0.21769990\n",
      "Iteration 162, loss = 0.22169682\n",
      "Iteration 163, loss = 0.21568335\n",
      "Iteration 164, loss = 0.21799031\n",
      "Iteration 165, loss = 0.21674615\n",
      "Iteration 166, loss = 0.22451220\n",
      "Iteration 167, loss = 0.22391917\n",
      "Iteration 168, loss = 0.24132756\n",
      "Iteration 169, loss = 0.22004014\n",
      "Iteration 170, loss = 0.21759139\n",
      "Iteration 171, loss = 0.21593110\n",
      "Iteration 172, loss = 0.20861768\n",
      "Iteration 173, loss = 0.20883156\n",
      "Iteration 174, loss = 0.21542381\n",
      "Iteration 175, loss = 0.21065220\n",
      "Iteration 176, loss = 0.21064242\n",
      "Iteration 177, loss = 0.21611106\n",
      "Iteration 178, loss = 0.20841702\n",
      "Iteration 179, loss = 0.20601393\n",
      "Iteration 180, loss = 0.21557627\n",
      "Iteration 181, loss = 0.20595468\n",
      "Iteration 182, loss = 0.20889085\n",
      "Iteration 183, loss = 0.20428837\n",
      "Iteration 184, loss = 0.23821691\n",
      "Iteration 185, loss = 0.21636150\n",
      "Iteration 186, loss = 0.21179952\n",
      "Iteration 187, loss = 0.20276026\n",
      "Iteration 188, loss = 0.20440868\n",
      "Iteration 189, loss = 0.21317098\n",
      "Iteration 190, loss = 0.20642471\n",
      "Iteration 191, loss = 0.19881503\n",
      "Iteration 192, loss = 0.19986201\n",
      "Iteration 193, loss = 0.19746093\n",
      "Iteration 194, loss = 0.20983782\n",
      "Iteration 195, loss = 0.19611936\n",
      "Iteration 196, loss = 0.21425766\n",
      "Iteration 197, loss = 0.20196455\n",
      "Iteration 198, loss = 0.19097031\n",
      "Iteration 199, loss = 0.19427405\n",
      "Iteration 200, loss = 0.19288848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.88      0.92        43\n",
      "         1.0       0.81      0.60      0.69        35\n",
      "         2.0       0.80      0.92      0.86        36\n",
      "         3.0       0.90      0.90      0.90        41\n",
      "         4.0       0.88      0.97      0.93        38\n",
      "         5.0       0.84      0.87      0.85        30\n",
      "         6.0       1.00      0.92      0.96        37\n",
      "         7.0       0.91      0.84      0.87        37\n",
      "         8.0       0.73      0.83      0.77        29\n",
      "         9.0       0.79      0.88      0.83        34\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.87      0.86      0.86       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\rish_env\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(do_prediction(X_train, Y_train, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneClassSVM(kernel = \"rbf\", gamma = \"scale\", nu = 0.001)\n",
    "model.fit(X_train)\n",
    "Y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  16,   66,  173,  194,  219,  297,  349,  448,  698,  779,  815,\n",
       "         836,  857,  921,  924,  996, 1028, 1090, 1182, 1193, 1263, 1318,\n",
       "        1340], dtype=int64),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_index = np.where(Y_train_pred == -1)\n",
    "anomalies_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = X_train.drop(X_train.index[anomalies_index])\n",
    "Y_train_new = Y_train.drop(Y_train.index[anomalies_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1414.0</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "      <td>1414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>5.193069</td>\n",
       "      <td>11.877652</td>\n",
       "      <td>11.888260</td>\n",
       "      <td>5.765205</td>\n",
       "      <td>1.380481</td>\n",
       "      <td>0.120934</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>1.961103</td>\n",
       "      <td>...</td>\n",
       "      <td>3.741867</td>\n",
       "      <td>0.198727</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.277935</td>\n",
       "      <td>5.519095</td>\n",
       "      <td>12.161245</td>\n",
       "      <td>11.756011</td>\n",
       "      <td>6.685290</td>\n",
       "      <td>2.009194</td>\n",
       "      <td>0.327440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.879753</td>\n",
       "      <td>4.721268</td>\n",
       "      <td>4.195154</td>\n",
       "      <td>4.220426</td>\n",
       "      <td>5.669729</td>\n",
       "      <td>3.337079</td>\n",
       "      <td>0.957083</td>\n",
       "      <td>0.070296</td>\n",
       "      <td>3.127041</td>\n",
       "      <td>...</td>\n",
       "      <td>4.939033</td>\n",
       "      <td>0.959608</td>\n",
       "      <td>0.026593</td>\n",
       "      <td>0.925296</td>\n",
       "      <td>5.064690</td>\n",
       "      <td>4.286885</td>\n",
       "      <td>4.926554</td>\n",
       "      <td>5.886215</td>\n",
       "      <td>4.000786</td>\n",
       "      <td>1.737028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
       "count     1414.0  1414.000000  1414.000000  1414.000000  1414.000000   \n",
       "mean         0.0     0.294201     5.193069    11.877652    11.888260   \n",
       "std          0.0     0.879753     4.721268     4.195154     4.220426   \n",
       "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
       "count  1414.000000  1414.000000  1414.000000  1414.000000  1414.000000  ...   \n",
       "mean      5.765205     1.380481     0.120934     0.003536     1.961103  ...   \n",
       "std       5.669729     3.337079     0.957083     0.070296     3.127041  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    14.000000  ...   \n",
       "\n",
       "         pixel_6_6    pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2  \\\n",
       "count  1414.000000  1414.000000  1414.000000  1414.000000  1414.000000   \n",
       "mean      3.741867     0.198727     0.000707     0.277935     5.519095   \n",
       "std       4.939033     0.959608     0.026593     0.925296     5.064690   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     9.750000   \n",
       "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
       "\n",
       "         pixel_7_3    pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7  \n",
       "count  1414.000000  1414.000000  1414.000000  1414.000000  1414.000000  \n",
       "mean     12.161245    11.756011     6.685290     2.009194     0.327440  \n",
       "std       4.286885     4.926554     5.886215     4.000786     1.737028  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      11.000000     9.000000     0.000000     0.000000     0.000000  \n",
       "50%      13.000000    13.000000     6.000000     0.000000     0.000000  \n",
       "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig =plt.figure(figsize = (11,11))\n",
    "X_train_new.iloc[:,:-1].kurtosis(axis=0).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pixel_0_0    0.000000\n",
       "pixel_0_1    3.999768\n",
       "pixel_0_2    0.594267\n",
       "pixel_0_3   -1.233392\n",
       "pixel_0_4   -1.134874\n",
       "               ...   \n",
       "pixel_7_3   -1.371713\n",
       "pixel_7_4   -1.180869\n",
       "pixel_7_5    0.262211\n",
       "pixel_7_6    2.211168\n",
       "pixel_7_7    6.390036\n",
       "Length: 64, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data_embedded_new = get_tsne(X_train_new)\n",
    "# get_plot(X_data_embedded_new, Y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.35178232\n",
      "Iteration 2, loss = 2.23815090\n",
      "Iteration 3, loss = 2.14296811\n",
      "Iteration 4, loss = 2.06441421\n",
      "Iteration 5, loss = 1.98299414\n",
      "Iteration 6, loss = 1.90701946\n",
      "Iteration 7, loss = 1.81257209\n",
      "Iteration 8, loss = 1.73920003\n",
      "Iteration 9, loss = 1.65330151\n",
      "Iteration 10, loss = 1.56401504\n",
      "Iteration 11, loss = 1.51274182\n",
      "Iteration 12, loss = 1.42650471\n",
      "Iteration 13, loss = 1.34669358\n",
      "Iteration 14, loss = 1.28026405\n",
      "Iteration 15, loss = 1.21565955\n",
      "Iteration 16, loss = 1.16628428\n",
      "Iteration 17, loss = 1.12074879\n",
      "Iteration 18, loss = 1.05998825\n",
      "Iteration 19, loss = 1.01380215\n",
      "Iteration 20, loss = 0.98953767\n",
      "Iteration 21, loss = 0.93993103\n",
      "Iteration 22, loss = 0.92581192\n",
      "Iteration 23, loss = 0.88346790\n",
      "Iteration 24, loss = 0.85161320\n",
      "Iteration 25, loss = 0.82214825\n",
      "Iteration 26, loss = 0.78687909\n",
      "Iteration 27, loss = 0.76381051\n",
      "Iteration 28, loss = 0.73809313\n",
      "Iteration 29, loss = 0.71869680\n",
      "Iteration 30, loss = 0.70315038\n",
      "Iteration 31, loss = 0.68406345\n",
      "Iteration 32, loss = 0.65854015\n",
      "Iteration 33, loss = 0.66425132\n",
      "Iteration 34, loss = 0.64244012\n",
      "Iteration 35, loss = 0.61920607\n",
      "Iteration 36, loss = 0.62271685\n",
      "Iteration 37, loss = 0.59542244\n",
      "Iteration 38, loss = 0.60394398\n",
      "Iteration 39, loss = 0.58319809\n",
      "Iteration 40, loss = 0.56503520\n",
      "Iteration 41, loss = 0.54145896\n",
      "Iteration 42, loss = 0.53187980\n",
      "Iteration 43, loss = 0.53884955\n",
      "Iteration 44, loss = 0.51892943\n",
      "Iteration 45, loss = 0.50622472\n",
      "Iteration 46, loss = 0.52158078\n",
      "Iteration 47, loss = 0.49603111\n",
      "Iteration 48, loss = 0.47959366\n",
      "Iteration 49, loss = 0.47840643\n",
      "Iteration 50, loss = 0.46495989\n",
      "Iteration 51, loss = 0.45671627\n",
      "Iteration 52, loss = 0.44673962\n",
      "Iteration 53, loss = 0.44071352\n",
      "Iteration 54, loss = 0.43366637\n",
      "Iteration 55, loss = 0.45555080\n",
      "Iteration 56, loss = 0.46870822\n",
      "Iteration 57, loss = 0.45801879\n",
      "Iteration 58, loss = 0.43449655\n",
      "Iteration 59, loss = 0.43133595\n",
      "Iteration 60, loss = 0.41853756\n",
      "Iteration 61, loss = 0.42687722\n",
      "Iteration 62, loss = 0.41227265\n",
      "Iteration 63, loss = 0.39448451\n",
      "Iteration 64, loss = 0.38733392\n",
      "Iteration 65, loss = 0.38471517\n",
      "Iteration 66, loss = 0.51018526\n",
      "Iteration 67, loss = 0.40249673\n",
      "Iteration 68, loss = 0.38588176\n",
      "Iteration 69, loss = 0.37655255\n",
      "Iteration 70, loss = 0.36472873\n",
      "Iteration 71, loss = 0.36037399\n",
      "Iteration 72, loss = 0.35781632\n",
      "Iteration 73, loss = 0.36027408\n",
      "Iteration 74, loss = 0.37252147\n",
      "Iteration 75, loss = 0.35902047\n",
      "Iteration 76, loss = 0.36772965\n",
      "Iteration 77, loss = 0.38152383\n",
      "Iteration 78, loss = 0.35901969\n",
      "Iteration 79, loss = 0.34720111\n",
      "Iteration 80, loss = 0.33321142\n",
      "Iteration 81, loss = 0.33522083\n",
      "Iteration 82, loss = 0.33647063\n",
      "Iteration 83, loss = 0.32518368\n",
      "Iteration 84, loss = 0.32626994\n",
      "Iteration 85, loss = 0.37640613\n",
      "Iteration 86, loss = 0.33818240\n",
      "Iteration 87, loss = 0.32988781\n",
      "Iteration 88, loss = 0.32251095\n",
      "Iteration 89, loss = 0.31714651\n",
      "Iteration 90, loss = 0.31546660\n",
      "Iteration 91, loss = 0.32416620\n",
      "Iteration 92, loss = 0.32692070\n",
      "Iteration 93, loss = 0.31770249\n",
      "Iteration 94, loss = 0.32270669\n",
      "Iteration 95, loss = 0.30940174\n",
      "Iteration 96, loss = 0.29884973\n",
      "Iteration 97, loss = 0.36881318\n",
      "Iteration 98, loss = 0.31978151\n",
      "Iteration 99, loss = 0.31293658\n",
      "Iteration 100, loss = 0.30946453\n",
      "Iteration 101, loss = 0.30678765\n",
      "Iteration 102, loss = 0.36555347\n",
      "Iteration 103, loss = 0.32267697\n",
      "Iteration 104, loss = 0.30559194\n",
      "Iteration 105, loss = 0.30456635\n",
      "Iteration 106, loss = 0.29369424\n",
      "Iteration 107, loss = 0.29097005\n",
      "Iteration 108, loss = 0.28231741\n",
      "Iteration 109, loss = 0.36350143\n",
      "Iteration 110, loss = 0.31694672\n",
      "Iteration 111, loss = 0.29283717\n",
      "Iteration 112, loss = 0.29335143\n",
      "Iteration 113, loss = 0.29197491\n",
      "Iteration 114, loss = 0.29734485\n",
      "Iteration 115, loss = 0.28431728\n",
      "Iteration 116, loss = 0.32210769\n",
      "Iteration 117, loss = 0.29061364\n",
      "Iteration 118, loss = 0.30718422\n",
      "Iteration 119, loss = 0.27686191\n",
      "Iteration 120, loss = 0.27466726\n",
      "Iteration 121, loss = 0.26429735\n",
      "Iteration 122, loss = 0.26389152\n",
      "Iteration 123, loss = 0.26384339\n",
      "Iteration 124, loss = 0.28113049\n",
      "Iteration 125, loss = 0.27582877\n",
      "Iteration 126, loss = 0.26623847\n",
      "Iteration 127, loss = 0.30904611\n",
      "Iteration 128, loss = 0.27734558\n",
      "Iteration 129, loss = 0.35468694\n",
      "Iteration 130, loss = 0.27952625\n",
      "Iteration 131, loss = 0.27749736\n",
      "Iteration 132, loss = 0.25871335\n",
      "Iteration 133, loss = 0.31228100\n",
      "Iteration 134, loss = 0.27624683\n",
      "Iteration 135, loss = 0.26798135\n",
      "Iteration 136, loss = 0.25509894\n",
      "Iteration 137, loss = 0.26838517\n",
      "Iteration 138, loss = 0.25309109\n",
      "Iteration 139, loss = 0.25157928\n",
      "Iteration 140, loss = 0.24520442\n",
      "Iteration 141, loss = 0.24163013\n",
      "Iteration 142, loss = 0.23649647\n",
      "Iteration 143, loss = 0.23664794\n",
      "Iteration 144, loss = 0.23445887\n",
      "Iteration 145, loss = 0.23528679\n",
      "Iteration 146, loss = 0.24965655\n",
      "Iteration 147, loss = 0.23734712\n",
      "Iteration 148, loss = 0.33176152\n",
      "Iteration 149, loss = 0.26751529\n",
      "Iteration 150, loss = 0.26396224\n",
      "Iteration 151, loss = 0.30573616\n",
      "Iteration 152, loss = 0.25784684\n",
      "Iteration 153, loss = 0.26693711\n",
      "Iteration 154, loss = 0.25849804\n",
      "Iteration 155, loss = 0.24157243\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93        43\n",
      "         1.0       0.74      0.57      0.65        35\n",
      "         2.0       0.80      0.92      0.86        36\n",
      "         3.0       1.00      0.90      0.95        41\n",
      "         4.0       0.88      1.00      0.94        38\n",
      "         5.0       0.93      0.90      0.92        30\n",
      "         6.0       1.00      0.92      0.96        37\n",
      "         7.0       0.83      0.92      0.87        37\n",
      "         8.0       0.67      0.90      0.76        29\n",
      "         9.0       0.93      0.76      0.84        34\n",
      "\n",
      "    accuracy                           0.87       360\n",
      "   macro avg       0.87      0.87      0.87       360\n",
      "weighted avg       0.88      0.87      0.87       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(do_prediction(X_train_new, Y_train_new, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data_embedded = get_tsne(X_train)\n",
    "# get_plot(X_data_embedded, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b1db67202a22c0164e18849e85225c385668d55f66b602110c77d4fc6f23f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
