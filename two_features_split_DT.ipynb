{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oJCvGKXAWf1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from treelib import Tree\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJQEku55AWf4"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, name, feature=None, threshold=None, left_child1=None, left_child2=None, right_child1=None, right_child2=None, is_leaf=False, value=-1, depth=-1):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left_child1 = left_child1\n",
        "        self.left_child2 = left_child2\n",
        "        self.right_child1 = right_child1\n",
        "        self.right_child2 = right_child2\n",
        "        self.is_leaf = is_leaf\n",
        "        self.value = value\n",
        "        self.name = name\n",
        "        self.depth = depth\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p51j4AzAWf5"
      },
      "outputs": [],
      "source": [
        "class MyDecisionTree:\n",
        "    def __init__(self, min_samples=1, max_depth=-1, max_thresholds=None, min_unique_values=None, num_random_columns=None):\n",
        "        self.root_node = Node('root', depth=0)\n",
        "        self.node_count = 0\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "        self.max_thresholds = max_thresholds\n",
        "        self.min_unique_values = min_unique_values\n",
        "        self.num_random_columns = num_random_columns\n",
        "    \n",
        "    def predict(self, X, cols_d):\n",
        "        \n",
        "        Y_pred = []\n",
        "        for i in range(len(X)):\n",
        "\n",
        "            x_i = X[i]\n",
        "            # print(x_i[0])\n",
        "            curr_node = self.root_node\n",
        "            predicted_y = np.array(self.predict_util(x_i, curr_node, cols_d))\n",
        "            # print(predicted_y)\n",
        "            Y_pred.append(predicted_y)\n",
        "\n",
        "        return np.array(Y_pred)\n",
        "\n",
        "    def predict_util(self, x, curr_node, cols_d):\n",
        "        \n",
        "        if(curr_node.is_leaf):\n",
        "            return curr_node.value\n",
        "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.left_child1, cols_d)\n",
        "\n",
        "        if x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] <= curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.left_child2, cols_d)\n",
        "\n",
        "        if x[cols_d[curr_node.feature[0]]] <= curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.right_child1, cols_d)\n",
        "\n",
        "        elif x[cols_d[curr_node.feature[0]]] > curr_node.threshold[0] and x[cols_d[curr_node.feature[1]]] > curr_node.threshold[1]:\n",
        "            if curr_node.is_leaf:\n",
        "                return curr_node.value\n",
        "            return self.predict_util(x, curr_node.right_child2, cols_d)\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.fit_util(X, Y, self.root_node)\n",
        "\n",
        "\n",
        "    def fit_util(self, X, Y, current_node):\n",
        "        if np.unique(Y).shape[0] == 1:\n",
        "            current_node.is_leaf = True\n",
        "            unq, counts = np.unique(Y, return_counts=True)\n",
        "            max_freq_idx = np.argmax(counts).flatten()\n",
        "            current_node.value = unq[max_freq_idx].squeeze()\n",
        "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
        "            self.node_count += 1\n",
        "            return\n",
        "            \n",
        "        scores = {}\n",
        "        num_random_columns = len(X.columns)\n",
        "        if self.num_random_columns is not None:\n",
        "            num_random_columns = self.num_random_columns\n",
        "        random_columns = X.columns.to_numpy()[np.random.permutation(len(X.columns))[:num_random_columns]]\n",
        "        \n",
        "        for column1 in random_columns:\n",
        "            for column2 in random_columns:\n",
        "                column = [column1, column2]\n",
        "                X_train = X[column].to_numpy()\n",
        "                X_train = X_train.reshape(X_train.shape[0], 2)\n",
        "                clf = LogisticRegression(random_state=0)\n",
        "                clf.fit(X_train, Y)\n",
        "                score = clf.score(X_train, Y)\n",
        "                scores[(column1, column2)] = score\n",
        "            \n",
        "\n",
        "        scores_sorted = dict( sorted(scores.items(), key=operator.itemgetter(1),reverse=True))\n",
        "        best_feature_set = list(scores_sorted.keys())[0]\n",
        "        best_feature1_values = np.unique(X[best_feature_set[0]])\n",
        "        best_feature2_values = np.unique(X[best_feature_set[1]])\n",
        "\n",
        "        best_feature1_values.sort()\n",
        "        best_feature2_values.sort()\n",
        "\n",
        "        partition = self.get_partition(X, Y, best_feature_set[0], best_feature_set[1], best_feature1_values, best_feature2_values, current_node.depth)\n",
        "        \n",
        "        if partition == None:\n",
        "            current_node.is_leaf = True\n",
        "            unq, counts = np.unique(Y, return_counts=True)\n",
        "            max_freq_idx = np.argmax(counts).flatten()\n",
        "            current_node.value = unq[max_freq_idx].squeeze()\n",
        "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
        "            self.node_count += 1\n",
        "            return\n",
        "            \n",
        "        (X_left1, Y_left1), (X_left2, Y_left2), (X_right1, Y_right1), (X_right2, Y_right2), threshold1, threshold2 = partition\n",
        "\n",
        "        threshold = [threshold1, threshold2]\n",
        "        # print(\"Thresholds: \",threshold)\n",
        "        current_node.threshold = threshold\n",
        "        current_node.feature = best_feature_set\n",
        "        current_node.name = f'{best_feature_set} {threshold} {self.node_count}'\n",
        "        self.node_count += 1\n",
        "        current_node.left_child1 = Node('unnamed', depth=current_node.depth + 1)\n",
        "        current_node.left_child2 = Node('unnamed', depth=current_node.depth + 1)\n",
        "        current_node.right_child1 = Node('unnamed', depth=current_node.depth + 1)\n",
        "        current_node.right_child2 = Node('unnamed', depth=current_node.depth + 1)\n",
        "\n",
        "        if(X_left1.shape[0] == 0):\n",
        "            current_node.left_child1.is_leaf = True\n",
        "            current_node.left_child1.value = 1\n",
        "            current_node.left_child1.name = f'leaf {current_node.left_child1.value} {self.node_count}'\n",
        "            self.node_count+=1 \n",
        "            # return\n",
        "        \n",
        "        if(X_left2.shape[0] == 0):\n",
        "            current_node.left_child2.is_leaf = True\n",
        "            current_node.left_child2.value = 1\n",
        "            current_node.left_child2.name = f'leaf {current_node.left_child2.value} {self.node_count}'\n",
        "            self.node_count+=1 \n",
        "            # return\n",
        "        \n",
        "        if(X_right1.shape[0] == 0):\n",
        "            current_node.right_child1.is_leaf = True\n",
        "            current_node.right_child1.value = 1\n",
        "            current_node.right_child1.name = f'leaf {current_node.right_child1.value} {self.node_count}'\n",
        "            self.node_count+=1   \n",
        "            # return     \n",
        "        \n",
        "        if(X_right2.shape[0] == 0):\n",
        "            current_node.right_child2.is_leaf = True\n",
        "            current_node.right_child2.value = 1\n",
        "            current_node.right_child2.name = f'leaf {current_node.right_child2.value} {self.node_count}'\n",
        "            self.node_count+=1  \n",
        "            # return                  \n",
        "          \n",
        "        if(X_left1.shape[0] != 0):\n",
        "            self.fit_util(X_left1, Y_left1, current_node.left_child1)\n",
        "        \n",
        "        if(X_left2.shape[0] != 0):\n",
        "            self.fit_util(X_left2, Y_left2, current_node.left_child2)\n",
        "        \n",
        "        if(X_right1.shape[0] != 0):\n",
        "            self.fit_util(X_right1, Y_right1, current_node.right_child1)\n",
        "        \n",
        "        if(X_right2.shape[0] != 0):\n",
        "            self.fit_util(X_right2, Y_right2, current_node.right_child2)\n",
        "\n",
        "\n",
        "    def do_split(self, X, thresh):\n",
        "        \"\"\"\n",
        "            Split the data at a node based on threshold\n",
        "        \"\"\"\n",
        "\n",
        "        left_child_ids = np.where(X <= thresh, True, False)\n",
        "        right_child_ids = np.where(X > thresh, True, False)\n",
        "        return left_child_ids, right_child_ids\n",
        "\n",
        "    def do_split_final(self, X1, X2, thresh1, thresh2):\n",
        "\n",
        "        \"\"\"\n",
        "            Split according to the best thresholds for the 2 features\n",
        "        \"\"\"   \n",
        "\n",
        "        left1_ids = np.where(np.logical_and(X1 <= thresh1, X2 <= thresh2), True, False)\n",
        "        left2_ids = np.where(np.logical_and(X1 > thresh1, X2 <= thresh2), True, False)\n",
        "        right1_ids = np.where(np.logical_and(X1 <= thresh1, X2 > thresh2), True, False)\n",
        "        right2_ids = np.where(np.logical_and(X1 > thresh1, X2 > thresh2), True, False)\n",
        "\n",
        "        return left1_ids, left2_ids, right1_ids, right2_ids\n",
        "\n",
        "    def find_entropy(self, Y):\n",
        "        probs = []\n",
        "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
        "        sort_indices = np.argsort(possible_classes)\n",
        "        possible_classes = possible_classes[sort_indices]\n",
        "        counts = counts[sort_indices]\n",
        "        \n",
        "        for class_label, count in zip(possible_classes, counts):\n",
        "            probs.append(count/Y.shape[0])\n",
        "        \n",
        "        entropy = 0\n",
        "        for prob in probs:\n",
        "            entropy -= prob*np.log2(prob)\n",
        "        \n",
        "        return entropy\n",
        "    \n",
        "    def find_best_thresh_info_gain(self, thresholds1, thresholds2, X, Y, feature1, feature2):\n",
        "        \"\"\"\n",
        "            This function finds the best threshold and info gain for a given feature\n",
        "        \"\"\"\n",
        "        best_info_gain = -float('inf')\n",
        "        best_thresh1 = thresholds1[0]   \n",
        "        best_thresh2 = thresholds2[0]     \n",
        "        threshold_cnt_1 = len(thresholds1)\n",
        "        threshold_cnt_2  = len(thresholds2)\n",
        "        if self.max_thresholds is not None:\n",
        "            threshold_cnt_1, threshold_cnt_2 = self.max_thresholds, self.max_thresholds\n",
        "        min_unique_values_1 = len(thresholds1)\n",
        "        min_unique_values_2 = len(thresholds2)\n",
        "\n",
        "        if self.min_unique_values is not None:\n",
        "            min_unique_values_1, min_unique_values_2 = self.min_unique_values, self.min_unique_values\n",
        "        \n",
        "        print(\"Now thresholding!\")\n",
        "        for thresh1 in (thresholds1[:-1] if len(thresholds1) <= min_unique_values_1 else thresholds1[:-1:len(thresholds1) // threshold_cnt_1]):\n",
        "            for thresh2 in (thresholds2[:-1] if len(thresholds2) <= min_unique_values_2 else thresholds2[:-1:len(thresholds2) // threshold_cnt_2]):\n",
        "                left_child1_ids, left_child2_ids,  right_child1_ids, right_child2_ids = self.do_split_final(X[feature1].to_numpy(),X[feature2].to_numpy(), thresh1, thresh2)\n",
        "\n",
        "                parent_pts = X.shape[0]\n",
        "                left_child1_pts = len(left_child1_ids)\n",
        "                left_child2_pts = len(left_child2_ids)\n",
        "                right_child1_pts = len(right_child1_ids)\n",
        "                right_child2_pts = len(right_child2_ids)\n",
        "\n",
        "                info_gain = self.find_entropy(Y) - (left_child1_pts / parent_pts) * self.find_entropy(Y[left_child1_ids]) - (left_child2_pts / parent_pts) * self.find_entropy(Y[left_child2_ids]) - (right_child1_pts / parent_pts) * self.find_entropy(Y[right_child1_ids]) - (right_child2_pts / parent_pts) * self.find_entropy(Y[right_child2_ids])\n",
        "                \n",
        "                if(info_gain > best_info_gain):\n",
        "\n",
        "                    best_info_gain = info_gain\n",
        "                    best_thresh1 = thresh1\n",
        "                    best_thresh2 = thresh2\n",
        "\n",
        "        \n",
        "        return best_thresh1, best_thresh2, best_info_gain\n",
        "\n",
        "    def get_partition(self, X, Y, feature1, feature2, thresholds1, thresholds2, current_node_depth):\n",
        "        '''\n",
        "            This function should return left and right\n",
        "            partitions according to appropritate\n",
        "            partitioning algorithm. Return None if all\n",
        "            data has same label\n",
        "        '''\n",
        "        \n",
        "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
        "        if(len(Y) < self.min_samples):\n",
        "            return None\n",
        "        if(current_node_depth == self.max_depth):\n",
        "            return None\n",
        "        \n",
        "        best_thresh1, best_thresh2, best_info_gain = self.find_best_thresh_info_gain(thresholds1, thresholds2, X, Y, feature1, feature2)\n",
        "\n",
        "        # partition according to best threshold\n",
        "        best_left_ids1, best_left_ids2, best_right_ids1, best_right_ids2 = self.do_split_final(X[feature1].to_numpy(), X[feature2].to_numpy(), best_thresh1, best_thresh2)\n",
        "\n",
        "        # print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
        "\n",
        "        count_0 = 0\n",
        "        if(len(Y[best_left_ids1]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_left_ids2]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_right_ids1]) == 0):\n",
        "            count_0 += 1\n",
        "        if(len(Y[best_right_ids2]) == 0):\n",
        "            count_0 += 1\n",
        "\n",
        "        if(count_0 == 3):\n",
        "            print(len(Y[best_left_ids1]), len(Y[best_left_ids2]), len(Y[best_right_ids1]) , len(Y[best_right_ids2]))\n",
        "            return None\n",
        "\n",
        "        return (X[best_left_ids1], Y[best_left_ids1]), (X[best_left_ids2], Y[best_left_ids2]), (X[best_right_ids1], Y[best_right_ids1]),(X[best_right_ids2], Y[best_right_ids2]), best_thresh1, best_thresh2    \n",
        "    \n",
        "    def print_tree(self):\n",
        "        tree = Tree()\n",
        "        self.print_tree_util(self.root_node, tree)\n",
        "        tree.show()\n",
        "        return tree\n",
        "\n",
        "    def print_tree_util(self, root, tree, parent=None):\n",
        "        if parent is not None:\n",
        "            print(root.name)\n",
        "            tree.create_node(root.name, root.name, parent=parent.name)\n",
        "        else:\n",
        "            print(root.name)\n",
        "            tree.create_node(root.name, root.name)\n",
        "        if root.is_leaf:\n",
        "            return\n",
        "        self.print_tree_util(root.left_child1, tree, root)\n",
        "        self.print_tree_util(root.left_child2, tree, root)\n",
        "        self.print_tree_util(root.right_child1, tree, root)\n",
        "        self.print_tree_util(root.right_child2, tree, root)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/final_data1.csv')\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_3 = pd.read_csv('./data/pre-processed_banking.csv')\n",
        "\n",
        "data_3 = pd.get_dummies(data_3, columns=['job',\n",
        "                                        'marital',\n",
        "                                        'education',\n",
        "                                        'housing',\n",
        "                                        'loan',\n",
        "                                        'contact',\n",
        "                                        'month',\n",
        "                                        'day_of_week',\n",
        "                                        'poutcome'])\n",
        "\n",
        "dt = MyDecisionTree(max_depth=5, min_unique_values=30)\n",
        "X = data_3.drop(['y'], axis=1)\n",
        "Y = data_3['y'].to_numpy()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "dt.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7usULr-ZAWf8"
      },
      "outputs": [],
      "source": [
        "dt = MyDecisionTree(max_depth=10, min_unique_values=30)\n",
        "X = df.drop(['Unnamed: 0', 'Biopsy'], axis=1)\n",
        "Y = df['Biopsy'].to_numpy()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "dt.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree = dt.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree.to_graphviz()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df.to_numpy())\n",
        "cols = X.columns\n",
        "cols_d = {}\n",
        "id=0\n",
        "for col in cols:\n",
        "    cols_d[col] = id\n",
        "    id+=1\n",
        "Y_pred = dt.predict(np.array(X_test.to_numpy()), cols_d)\n",
        "Y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = (Y_pred == Y_test).sum() / Y_test.shape[0]\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXI_bD3yJ1kG",
        "outputId": "4a68ad85-f1f2-44be-9223-594f7de05da8"
      },
      "outputs": [],
      "source": [
        "digits = load_digits()\n",
        "X_digits, Y_digits = digits.data, digits.target\n",
        "X_digits = X_digits/255\n",
        "X_digits_train,X_digits_test,Y_digits_train,Y_digits_test=train_test_split(X_digits,Y_digits,test_size=0.2,random_state=42)\n",
        "X_digits_train = pd.DataFrame(X_digits_train)\n",
        "X_digits_test = pd.DataFrame(X_digits_test)\n",
        "\n",
        "print(X_digits_train.shape)\n",
        "print(X_digits_test.shape)\n",
        "\n",
        "# X_iris = pd.DataFrame(X_iris)\n",
        "# print(X_iris.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWfLDmLsJ4Gd",
        "outputId": "9648b4b0-16f4-4012-d524-8c9613c21bc9"
      },
      "outputs": [],
      "source": [
        "dt_digits = MyDecisionTree(min_samples=1)\n",
        "dt_digits.fit(X_digits_train, Y_digits_train)\n",
        "tree = dt_digits.print_tree()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1jbUJe-M5TL",
        "outputId": "32236e20-486d-451e-a4aa-268f3bb19053"
      },
      "outputs": [],
      "source": [
        "tree.to_graphviz()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7isM0SHJ74H",
        "outputId": "7bfb7f86-b67f-485d-f9fb-377a7633b5e5"
      },
      "outputs": [],
      "source": [
        "pred_y_digits = dt_digits.predict(X_digits_test.to_numpy()).squeeze()\n",
        "# print(pred_y_digits)\n",
        "\n",
        "accuracy = (pred_y_digits == Y_digits_test).sum() / Y_digits_test.shape[0]\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(Y_pred, Y_test)\n",
        "f1 = f1_score(Y_pred, Y_test)\n",
        "precision = precision_score(Y_pred, Y_test)\n",
        "recall = recall_score(Y_pred, Y_test)\n",
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('computer_vision')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "85b1db67202a22c0164e18849e85225c385668d55f66b602110c77d4fc6f23f4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
