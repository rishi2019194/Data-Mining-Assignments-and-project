{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, threshold, left_child=None, right_child=None, is_leaf=False):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.is_leaf = is_leaf\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x[self.feature] < self.threshold:\n",
    "            if self.is_leaf:\n",
    "                return self.left_child\n",
    "            return self.left_child.forward(x)\n",
    "        else:\n",
    "            if self.is_leaf:\n",
    "                return self.right_child\n",
    "            return self.right_child.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import null_debug_action\n",
    "\n",
    "\n",
    "class MyDecisionTree:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        scores = []\n",
    "        for column in X.columns:\n",
    "            X_train = X[column].to_numpy()\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "            clf = LogisticRegression(random_state=0)\n",
    "            clf.fit(X_train, Y)\n",
    "            score = clf.score(X_train, Y)\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        best_feature = X.columns[np.argmax(scores)]\n",
    "        print(best_feature)\n",
    "        print(scores)\n",
    "\n",
    "    def do_split(self, X, thresh):\n",
    "        \"\"\"\n",
    "            Split the data at a node based on threshold\n",
    "        \"\"\"\n",
    "\n",
    "        left_child_ids = np.where(X<=thresh).flatten()\n",
    "        right_child_ids = np.where(X>thresh).flatten()\n",
    "        return left_child_ids, right_child_ids\n",
    "    \n",
    "    def find_entropy(self, y):\n",
    "        probs = []\n",
    "        for i in range(len(y)):\n",
    "            probs.append(y[i]/len(y))\n",
    "        \n",
    "        entropy = 0\n",
    "        for i in range(len(probs)):\n",
    "            entropy -= probs[i]*np.log2(p)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def get_partition(self, X, Y, feature, threshold):\n",
    "        '''\n",
    "            This function should return left and right\n",
    "            partitions according to appropritate\n",
    "            partitioning algorithm. Return None if all\n",
    "            data has same label\n",
    "        '''\n",
    "\n",
    "        if(len(np.unique(Y)) == 1):\n",
    "            return None\n",
    "        \n",
    "        best_info_gain = -1\n",
    "        best_thresh = threshold[0]\n",
    "        for thresh in threshold:\n",
    "\n",
    "            left_child_ids, right_child_ids = self.do_split(X, thresh)\n",
    "            parent_pts = len(X)\n",
    "            left_child_pts = len(left_child_ids)\n",
    "            right_child_pts = len(right_child_ids)\n",
    "\n",
    "            info_gain = 1 - left_child_pts/parent_pts*self.find_entropy(Y[left_child_ids]) - right_child_pts/parent_pts*self.find_entropy(Y[right_child_ids])\n",
    "\n",
    "            if(info_gain > best_info_gain):\n",
    "\n",
    "                best_info_gain = info_gain\n",
    "                best_thresh = thresh\n",
    "        \n",
    "        # partition according to best threshold\n",
    "        best_left_ids, best_right_ids = self.do_split(X, best_thresh)\n",
    "        return (X[best_left_ids], Y[best_left_ids]), (X[best_right_ids], Y[best_right_ids]), best_thresh\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = MyDecisionTree()\n",
    "X = df.loc[:, df.columns != 'Biopsy']\n",
    "Y = df['Biopsy'].to_numpy()\n",
    "dt.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0.74666667 0.55333333 0.95333333 0.96      ]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "Y_iris = iris.target\n",
    "X_iris = pd.DataFrame(X_iris)\n",
    "dt_iris = MyDecisionTree()\n",
    "dt_iris.fit(X_iris, Y_iris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b1db67202a22c0164e18849e85225c385668d55f66b602110c77d4fc6f23f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
