{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from treelib import Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, name, feature=None, threshold=None, left_child=None, right_child=None, is_leaf=False, value=-1):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.is_leaf = is_leaf\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(self.feature)\n",
    "        if x[self.feature] < self.threshold:\n",
    "            if self.is_leaf:\n",
    "                return self.value\n",
    "            return self.left_child.forward(x)\n",
    "        else:\n",
    "            if self.is_leaf:\n",
    "                return self.value\n",
    "            return self.right_child.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self, min_samples=1):\n",
    "        self.root_node = Node('root')\n",
    "        self.node_count = 0\n",
    "        self.min_samples = min_samples\n",
    "    \n",
    "    def predict(self, X, cols_d):\n",
    "        \n",
    "        Y_pred = []\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            x_i = X[i]\n",
    "            # print(x_i[0])\n",
    "            curr_node = self.root_node\n",
    "            predicted_y = np.array(self.predict_util(x_i, curr_node, cols_d))\n",
    "            # print(predicted_y)\n",
    "            Y_pred.append(predicted_y)\n",
    "\n",
    "        return np.array(Y_pred)\n",
    "\n",
    "    def predict_util(self, x, curr_node, cols_d):\n",
    "        \n",
    "        print(curr_node.feature)\n",
    "        if(curr_node.is_leaf):\n",
    "            return curr_node.value\n",
    "        if x[cols_d[curr_node.feature]] <= curr_node.threshold:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.left_child, cols_d)\n",
    "        else:\n",
    "            if curr_node.is_leaf:\n",
    "                return curr_node.value\n",
    "            return self.predict_util(x, curr_node.right_child, cols_d)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.fit_util(X, Y, self.root_node)\n",
    "\n",
    "\n",
    "    def fit_util(self, X, Y, current_node):\n",
    "        if np.unique(Y).shape[0] == 1:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        scores = []\n",
    "        for column in X.columns:\n",
    "            X_train = X[column].to_numpy()\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1)\n",
    "            clf = LogisticRegression(random_state=0, max_iter=100)\n",
    "            clf.fit(X_train, Y)\n",
    "            score = clf.score(X_train, Y)\n",
    "            scores.append(score)\n",
    "        scores = np.array(scores)\n",
    "        best_feature = X.columns[np.argmax(scores)]\n",
    "        best_feature_values = np.unique(X[best_feature])\n",
    "        best_feature_values.sort()\n",
    "\n",
    "        partition = self.get_partition(X, Y, best_feature, best_feature_values)\n",
    "        \n",
    "        if partition == None:\n",
    "            current_node.is_leaf = True\n",
    "            unq, counts = np.unique(Y, return_counts=True)\n",
    "            max_freq_idx = np.argmax(counts).flatten()\n",
    "            current_node.value = unq[max_freq_idx].squeeze()\n",
    "            current_node.name = f'leaf {current_node.value} {self.node_count}'\n",
    "            self.node_count += 1\n",
    "            return\n",
    "            \n",
    "        (X_left, Y_left), (X_right, Y_right), threshold = partition\n",
    "        current_node.threshold = threshold\n",
    "        current_node.feature = best_feature\n",
    "        current_node.name = f'{best_feature} {threshold} {self.node_count}'\n",
    "        self.node_count += 1\n",
    "        current_node.left_child = Node('No name')\n",
    "        current_node.right_child = Node('No name')\n",
    "\n",
    "        self.fit_util(X_left, Y_left, current_node.left_child)\n",
    "        self.fit_util(X_right, Y_right, current_node.right_child)\n",
    "\n",
    "        \n",
    "\n",
    "    def do_split(self, X, thresh):\n",
    "        \"\"\"\n",
    "            Split the data at a node based on threshold\n",
    "        \"\"\"\n",
    "\n",
    "        left_child_ids = np.where(X <= thresh, True, False)\n",
    "        right_child_ids = np.where(X > thresh, True, False)\n",
    "        return left_child_ids, right_child_ids\n",
    "    \n",
    "    def find_entropy(self, Y):\n",
    "        probs = []\n",
    "        possible_classes, counts = np.unique(Y, return_counts=True)\n",
    "        sort_indices = np.argsort(possible_classes)\n",
    "        possible_classes = possible_classes[sort_indices]\n",
    "        counts = counts[sort_indices]\n",
    "        \n",
    "        for class_label, count in zip(possible_classes, counts):\n",
    "            probs.append(count/Y.shape[0])\n",
    "        \n",
    "        entropy = 0\n",
    "        for prob in probs:\n",
    "            entropy -= prob*np.log2(prob)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def get_partition(self, X, Y, feature, thresholds):\n",
    "        '''\n",
    "            This function should return left and right\n",
    "            partitions according to appropritate\n",
    "            partitioning algorithm. Return None if all\n",
    "            data has same label\n",
    "        '''\n",
    "        \n",
    "        # if only 1 class available at a node OR MIN_SAMPLES left at a node - Leaf Node reached\n",
    "        if(len(Y) < self.min_samples):\n",
    "            return None\n",
    "        \n",
    "        best_info_gain = -float('inf')\n",
    "        best_thresh = thresholds[0]        \n",
    "        for thresh in thresholds[:-1]:\n",
    "\n",
    "            left_child_ids, right_child_ids = self.do_split(X[feature].to_numpy(), thresh)\n",
    "\n",
    "            parent_pts = X.shape[0]\n",
    "            left_child_pts = len(left_child_ids)\n",
    "            right_child_pts = len(right_child_ids)\n",
    "\n",
    "            info_gain = self.find_entropy(Y) - (left_child_pts / parent_pts) * self.find_entropy(Y[left_child_ids]) - (right_child_pts / parent_pts) * self.find_entropy(Y[right_child_ids])\n",
    "\n",
    "            if(info_gain > best_info_gain):\n",
    "\n",
    "                best_info_gain = info_gain\n",
    "                best_thresh = thresh\n",
    "        \n",
    "        # partition according to best threshold\n",
    "        best_left_ids, best_right_ids = self.do_split(X[feature].to_numpy(), best_thresh)\n",
    "        print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "        if(len(Y[best_left_ids]) == 0 or len(Y[best_right_ids]) == 0):\n",
    "            print(len(Y[best_left_ids]), len(Y[best_right_ids]))\n",
    "            return None\n",
    "        return (X[best_left_ids], Y[best_left_ids]), (X[best_right_ids], Y[best_right_ids]), best_thresh\n",
    "    \n",
    "    def print_tree(self):\n",
    "        tree = Tree()\n",
    "        self.print_tree_util(self.root_node, tree)\n",
    "        tree.show()\n",
    "        return tree\n",
    "\n",
    "    def print_tree_util(self, root, tree, parent=None):\n",
    "        if parent is not None:\n",
    "            tree.create_node(root.name, root.name, parent=parent.name)\n",
    "        else:\n",
    "            tree.create_node(root.name, root.name)\n",
    "        if root.is_leaf:\n",
    "            return\n",
    "        self.print_tree_util(root.left_child, tree, root)\n",
    "        self.print_tree_util(root.right_child, tree, root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Age', 'Number of sexual partners',\n",
       "       'First sexual intercourse', 'Num of pregnancies', 'Smokes',\n",
       "       'Smokes (years)', 'Smokes (packs/year)', 'Hormonal Contraceptives',\n",
       "       'Hormonal Contraceptives (years)', 'IUD', 'IUD (years)', 'STDs',\n",
       "       'STDs (number)', 'STDs:condylomatosis', 'STDs:cervical condylomatosis',\n",
       "       'STDs:vaginal condylomatosis', 'STDs:vulvo-perineal condylomatosis',\n",
       "       'STDs:syphilis', 'STDs:pelvic inflammatory disease',\n",
       "       'STDs:genital herpes', 'STDs:molluscum contagiosum', 'STDs:AIDS',\n",
       "       'STDs:HIV', 'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis',\n",
       "       'STDs: Time since first diagnosis', 'STDs: Time since last diagnosis',\n",
       "       'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Hinselmann', 'Schiller',\n",
       "       'Citology', 'Biopsy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686, 35)\n",
      "629 57\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import test\n",
    "\n",
    "\n",
    "dt = MyDecisionTree(min_samples = 686)\n",
    "X = df.drop(['Unnamed: 0', 'Biopsy'], axis=1)\n",
    "Y = df['Biopsy'].to_numpy()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161  11]\n"
     ]
    }
   ],
   "source": [
    "unq, counts = np.unique(Y_test, return_counts=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schiller 0 0\n",
      "├── leaf 0 1\n",
      "└── leaf 1 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X_digits, Y_digits = digits.data, digits.target\n",
    "X_digits = X_digits/255\n",
    "X_digits_train,X_digits_test,Y_digits_train,Y_digits_test=train_test_split(X_digits,Y_digits,test_size=0.2,random_state=42)\n",
    "X_digits_train = pd.DataFrame(X_digits_train)\n",
    "X_digits_test = pd.DataFrame(X_digits_test)\n",
    "\n",
    "print(X_digits_train.shape)\n",
    "print(X_digits_test.shape)\n",
    "\n",
    "# X_iris = pd.DataFrame(X_iris)\n",
    "# print(X_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372 1065\n",
      "372 0\n",
      "372 0\n",
      "249 816\n",
      "249 0\n",
      "249 0\n",
      "276 540\n",
      "276 0\n",
      "276 0\n",
      "540 0\n",
      "540 0\n",
      "34 0.0 0\n",
      "├── 53 0.0 2\n",
      "│   ├── 21 0.0 4\n",
      "│   │   ├── leaf 0 6\n",
      "│   │   └── leaf 6 5\n",
      "│   └── leaf 7 3\n",
      "└── leaf 3 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_digits = MyDecisionTree(min_samples=1)\n",
    "dt_digits.fit(X_digits_train, Y_digits_train)\n",
    "tree = dt_digits.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3472222222222222\n"
     ]
    }
   ],
   "source": [
    "pred_y_digits = dt_digits.predict(X_digits_test.to_numpy()).squeeze()\n",
    "# print(pred_y_digits)\n",
    "\n",
    "accuracy = (pred_y_digits == Y_digits_test).sum() / Y_digits_test.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph tree {\n",
      "\t\"3 0.6 0\" [label=\"3 0.6 0\", shape=circle]\n",
      "\t\"3 1.7 2\" [label=\"3 1.7 2\", shape=circle]\n",
      "\t\"leaf 0 1\" [label=\"leaf 0 1\", shape=circle]\n",
      "\t\"0 5.6 20\" [label=\"0 5.6 20\", shape=circle]\n",
      "\t\"2 5.1 3\" [label=\"2 5.1 3\", shape=circle]\n",
      "\t\"0 5.7 22\" [label=\"0 5.7 22\", shape=circle]\n",
      "\t\"leaf 2 21\" [label=\"leaf 2 21\", shape=circle]\n",
      "\t\"0 6.9 4\" [label=\"0 6.9 4\", shape=circle]\n",
      "\t\"leaf 2 19\" [label=\"leaf 2 19\", shape=circle]\n",
      "\t\"0 5.8 24\" [label=\"0 5.8 24\", shape=circle]\n",
      "\t\"leaf 2 23\" [label=\"leaf 2 23\", shape=circle]\n",
      "\t\"0 6.7 5\" [label=\"0 6.7 5\", shape=circle]\n",
      "\t\"leaf 1 18\" [label=\"leaf 1 18\", shape=circle]\n",
      "\t\"0 7.6 26\" [label=\"0 7.6 26\", shape=circle]\n",
      "\t\"leaf 2 25\" [label=\"leaf 2 25\", shape=circle]\n",
      "\t\"0 6.6 6\" [label=\"0 6.6 6\", shape=circle]\n",
      "\t\"leaf 1 17\" [label=\"leaf 1 17\", shape=circle]\n",
      "\t\"leaf 2 27\" [label=\"leaf 2 27\", shape=circle]\n",
      "\t\"leaf 2 28\" [label=\"leaf 2 28\", shape=circle]\n",
      "\t\"0 6.5 7\" [label=\"0 6.5 7\", shape=circle]\n",
      "\t\"leaf 1 16\" [label=\"leaf 1 16\", shape=circle]\n",
      "\t\"0 6.4 8\" [label=\"0 6.4 8\", shape=circle]\n",
      "\t\"leaf 1 15\" [label=\"leaf 1 15\", shape=circle]\n",
      "\t\"0 6.3 9\" [label=\"0 6.3 9\", shape=circle]\n",
      "\t\"leaf 1 14\" [label=\"leaf 1 14\", shape=circle]\n",
      "\t\"0 5.6 10\" [label=\"0 5.6 10\", shape=circle]\n",
      "\t\"leaf 1 13\" [label=\"leaf 1 13\", shape=circle]\n",
      "\t\"leaf 1 11\" [label=\"leaf 1 11\", shape=circle]\n",
      "\t\"leaf 1 12\" [label=\"leaf 1 12\", shape=circle]\n",
      "\n",
      "\t\"3 0.6 0\" -> \"leaf 0 1\"\n",
      "\t\"3 0.6 0\" -> \"3 1.7 2\"\n",
      "\t\"3 1.7 2\" -> \"2 5.1 3\"\n",
      "\t\"3 1.7 2\" -> \"0 5.6 20\"\n",
      "\t\"0 5.6 20\" -> \"leaf 2 21\"\n",
      "\t\"0 5.6 20\" -> \"0 5.7 22\"\n",
      "\t\"2 5.1 3\" -> \"0 6.9 4\"\n",
      "\t\"2 5.1 3\" -> \"leaf 2 19\"\n",
      "\t\"0 5.7 22\" -> \"leaf 2 23\"\n",
      "\t\"0 5.7 22\" -> \"0 5.8 24\"\n",
      "\t\"0 6.9 4\" -> \"0 6.7 5\"\n",
      "\t\"0 6.9 4\" -> \"leaf 1 18\"\n",
      "\t\"0 5.8 24\" -> \"leaf 2 25\"\n",
      "\t\"0 5.8 24\" -> \"0 7.6 26\"\n",
      "\t\"0 6.7 5\" -> \"0 6.6 6\"\n",
      "\t\"0 6.7 5\" -> \"leaf 1 17\"\n",
      "\t\"0 7.6 26\" -> \"leaf 2 27\"\n",
      "\t\"0 7.6 26\" -> \"leaf 2 28\"\n",
      "\t\"0 6.6 6\" -> \"0 6.5 7\"\n",
      "\t\"0 6.6 6\" -> \"leaf 1 16\"\n",
      "\t\"0 6.5 7\" -> \"0 6.4 8\"\n",
      "\t\"0 6.5 7\" -> \"leaf 1 15\"\n",
      "\t\"0 6.4 8\" -> \"0 6.3 9\"\n",
      "\t\"0 6.4 8\" -> \"leaf 1 14\"\n",
      "\t\"0 6.3 9\" -> \"0 5.6 10\"\n",
      "\t\"0 6.3 9\" -> \"leaf 1 13\"\n",
      "\t\"0 5.6 10\" -> \"leaf 1 11\"\n",
      "\t\"0 5.6 10\" -> \"leaf 1 12\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tree.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.  18.   4. ...   0.   0.   0.]\n",
      " [  1.  15.   1. ...   0.   0.   0.]\n",
      " [  2.  34.   1. ...   0.   0.   0.]\n",
      " ...\n",
      " [855.  25.   2. ...   0.   1.   0.]\n",
      " [856.  33.   2. ...   0.   0.   0.]\n",
      " [857.  29.   2. ...   0.   0.   0.]]\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n",
      "Schiller\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(df.to_numpy())\n",
    "cols = df.columns\n",
    "cols_d = {}\n",
    "id=0\n",
    "for col in cols:\n",
    "    cols_d[col] = id\n",
    "    id+=1\n",
    "Y_pred = dt.predict(np.array(X_test.to_numpy()), cols_d)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "accuracy = (Y_pred == Y_test).sum() / Y_test.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936046511627907"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "161/172"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('computer_vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85b1db67202a22c0164e18849e85225c385668d55f66b602110c77d4fc6f23f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
